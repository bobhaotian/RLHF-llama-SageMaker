{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7c1e11-a4db-47ac-a23f-051449e10c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "autogluon-multimodal 1.1.1 requires accelerate<0.22.0,>=0.21.0, but you have accelerate 1.9.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires transformers[sentencepiece]<4.41.0,>=4.38.0, but you have transformers 4.53.2 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires accelerate<0.22.0,>=0.21.0, but you have accelerate 1.9.0 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires transformers[sentencepiece]<4.41.0,>=4.38.0, but you have transformers 4.53.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 1. Pip install once per kernel  (≈ 1-2 min)\n",
    "# ================================================================\n",
    "!pip install -qU trl transformers datasets peft accelerate --extra-index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c3f30f3-9d13-4cd9-a6b0-5c86bb85e75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Cannot install accelerate==0.26.1 and trl==0.19.1 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# clean out any mismatching Accelerate first\n",
    "!pip uninstall -y accelerate\n",
    "\n",
    "# install a version in the allowed window, plus the other libs\n",
    "!pip install -q \"transformers==4.40.1\" \"accelerate==0.26.1\" \"trl==0.19.1\" \"peft\" \"datasets\" --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02ab4710-521d-479a-bf21-22843335b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping trl as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: transformers 4.49.0\n",
      "Uninstalling transformers-4.49.0:\n",
      "  Successfully uninstalled transformers-4.49.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires accelerate<0.22.0,>=0.21.0, which is not installed.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "autogluon-timeseries 1.1.1 requires accelerate<0.22.0,>=0.21.0, which is not installed.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y accelerate trl transformers\n",
    "#!pip install -q \"transformers==4.49.0\"\n",
    "!pip install -q \"transformers==4.39.3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3fcde9-48e9-4416-86cd-b3ce7cff913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: autogluon.multimodal 1.1.1\n",
      "Uninstalling autogluon.multimodal-1.1.1:\n",
      "  Successfully uninstalled autogluon.multimodal-1.1.1\n",
      "Found existing installation: autogluon.timeseries 1.1.1\n",
      "Uninstalling autogluon.timeseries-1.1.1:\n",
      "  Successfully uninstalled autogluon.timeseries-1.1.1\n",
      "Found existing installation: gluonts 0.14.3\n",
      "Uninstalling gluonts-0.14.3:\n",
      "  Successfully uninstalled gluonts-0.14.3\n",
      "\u001b[33mWARNING: Skipping nvidia-ml-py3 as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate>=0.27\n",
      "  Using cached accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl==0.19.1\n",
      "  Using cached trl-0.19.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting datasets>=3.0.0 (from trl==0.19.1)\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers>=4.51.0 (from trl==0.19.1)\n",
      "  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.27) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.27) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.27) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.27) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.27) (2.3.1.post100)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.27) (0.33.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.27) (0.4.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl==0.19.1) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl==0.19.1) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl==0.19.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl==0.19.1) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl==0.19.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl==0.19.1) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl==0.19.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl==0.19.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.27) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.27) (1.1.5)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.27) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.27) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.27) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.51.0->trl==0.19.1) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.51.0->trl==0.19.1) (0.21.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.19.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.19.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.19.1) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.19.1) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.27) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl==0.19.1) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl==0.19.1) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl==0.19.1) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0.0->accelerate>=0.27) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl==0.19.1) (1.16.0)\n",
      "Using cached trl-0.19.1-py3-none-any.whl (376 kB)\n",
      "Using cached accelerate-1.9.0-py3-none-any.whl (367 kB)\n",
      "Using cached datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "Installing collected packages: accelerate, transformers, datasets, trl\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.49.0\n",
      "    Uninstalling transformers-4.49.0:\n",
      "      Successfully uninstalled transformers-4.49.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.21.0\n",
      "    Uninstalling datasets-2.21.0:\n",
      "      Successfully uninstalled datasets-2.21.0\n",
      "Successfully installed accelerate-1.9.0 datasets-4.0.0 transformers-4.53.2 trl-0.19.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y accelerate\n",
    "!pip uninstall -y autogluon-multimodal autogluon-timeseries gluonts nvidia-ml-py3\n",
    "!pip install -U \"accelerate>=0.27\" \"trl==0.19.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90551668-bc4d-461a-99df-141f2aa8e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers 4.39.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(\"transformers\", transformers.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e112a04-60d5-48c0-a04b-4ff630fd5cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::842747873802:role/service-role/AmazonSageMaker-ExecutionRole-20250624T170706 sagemaker-us-west-2-842747873802 us-west-2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================================================\n",
    "# 0. House-keeping:  choose a role, bucket and paths\n",
    "# ================================================================\n",
    "import sagemaker, boto3, json, os, pathlib, time\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()                    # studio-execution-role\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()                           # or hard-code yours\n",
    "prefix = \"llama3_math_rlhf\"                              # keep all assets here\n",
    "\n",
    "BASE_ID = \"meta-textgeneration-llama-3-8b\"    # JumpStart Neuron model\n",
    "print(role, bucket, region)\n",
    "s3_rm = f\"s3://{bucket}/{prefix}/data/rm.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6dccfcd-31a8-4b7c-9676-95a6b34ac609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_reward.py\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0383a668-c694-4d3b-a92c-ea5e809a72f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m      5\u001b[0m sess   \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mSession()\n\u001b[1;32m      7\u001b[0m reward_est \u001b[38;5;241m=\u001b[39m HuggingFace(\n\u001b[1;32m      8\u001b[0m     entry_point         \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_reward.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     source_dir          \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m,          \u001b[38;5;66;03m# has script + requirements.txt\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     }\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m \u001b[43mreward_est\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrm-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m rm_uri \u001b[38;5;241m=\u001b[39m reward_est\u001b[38;5;241m.\u001b[39mmodel_data\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReward model artefact:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rm_uri)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:1344\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;129m@runnable_by_pipeline\u001b[39m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     experiment_config: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1287\u001b[0m ):\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a model using the input training dataset.\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \n\u001b[1;32m   1290\u001b[0m \u001b[38;5;124;03m    The API calls the Amazon SageMaker CreateTrainingJob API to start\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;124;03m        :class:`~sagemaker.workflow.pipeline_context.PipelineSession`\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m     experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job \u001b[38;5;241m=\u001b[39m _TrainingJob\u001b[38;5;241m.\u001b[39mstart_new(\u001b[38;5;28mself\u001b[39m, inputs, experiment_config)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:3559\u001b[0m, in \u001b[0;36mFramework._prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m   3551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_for_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3552\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set hyperparameters needed for training. This method will also validate ``source_dir``.\u001b[39;00m\n\u001b[1;32m   3553\u001b[0m \n\u001b[1;32m   3554\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3557\u001b[0m \u001b[38;5;124;03m            constructor if applicable.\u001b[39;00m\n\u001b[1;32m   3558\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3559\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFramework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3561\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_set_debugger_configs()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:942\u001b[0m, in \u001b[0;36mEstimatorBase._prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muploaded_code\u001b[38;5;241m.\u001b[39ms3_prefix\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muploaded_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stage_user_code_in_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m     code_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muploaded_code\u001b[38;5;241m.\u001b[39ms3_prefix\n\u001b[1;32m    944\u001b[0m     script \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muploaded_code\u001b[38;5;241m.\u001b[39mscript_name\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:1024\u001b[0m, in \u001b[0;36mEstimatorBase._stage_user_code_in_s3\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m             output_bucket, _ \u001b[38;5;241m=\u001b[39m parse_s3_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_path)\n\u001b[1;32m   1022\u001b[0m             kms_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_kms_key \u001b[38;5;28;01mif\u001b[39;00m code_bucket \u001b[38;5;241m==\u001b[39m output_bucket \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtar_and_upload_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboto_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_bucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_s3_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscript\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdependencies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms3_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/fw_utils.py:456\u001b[0m, in \u001b[0;36mtar_and_upload_dir\u001b[0;34m(session, bucket, s3_key_prefix, script, directory, dependencies, kms_key, s3_resource, settings)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     source_files \u001b[38;5;241m=\u001b[39m _list_files_to_compress(script, directory) \u001b[38;5;241m+\u001b[39m dependencies\n\u001b[0;32m--> 456\u001b[0m     tar_file \u001b[38;5;241m=\u001b[39m \u001b[43msagemaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_tar_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_TAR_SOURCE_FILENAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kms_key:\n\u001b[1;32m    461\u001b[0m         extra_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mServerSideEncryption\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maws:kms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSEKMSKeyId\u001b[39m\u001b[38;5;124m\"\u001b[39m: kms_key}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/utils.py:461\u001b[0m, in \u001b[0;36mcreate_tar_file\u001b[0;34m(source_files, target)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(filename, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw:gz\u001b[39m\u001b[38;5;124m\"\u001b[39m, dereference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sf \u001b[38;5;129;01min\u001b[39;00m source_files:\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;66;03m# Add all files from the directory into the root of the directory structure of the tar\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marcname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filename\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/tarfile.py:2187\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   2185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recursive:\n\u001b[1;32m   2186\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(name)):\n\u001b[0;32m-> 2187\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43marcname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2188\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/tarfile.py:2187\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   2185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recursive:\n\u001b[1;32m   2186\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(name)):\n\u001b[0;32m-> 2187\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43marcname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2188\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/tarfile.py:2187\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   2185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recursive:\n\u001b[1;32m   2186\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(name)):\n\u001b[0;32m-> 2187\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43marcname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2188\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/tarfile.py:2181\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misreg():\n\u001b[1;32m   2180\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m bltn_open(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m-> 2181\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misdir():\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/tarfile.py:2209\u001b[0m, in \u001b[0;36mTarFile.addfile\u001b[0;34m(self, tarinfo, fileobj)\u001b[0m\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;66;03m# If there's data to follow, append it.\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2209\u001b[0m     \u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2210\u001b[0m     blocks, remainder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(tarinfo\u001b[38;5;241m.\u001b[39msize, BLOCKSIZE)\n\u001b[1;32m   2211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remainder \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/tarfile.py:255\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buf) \u001b[38;5;241m<\u001b[39m bufsize:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected end of data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 255\u001b[0m     \u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remainder \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    258\u001b[0m     buf \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mread(remainder)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/gzip.py:289\u001b[0m, in \u001b[0;36mGzipFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    286\u001b[0m     length \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnbytes\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfileobj\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m length\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcrc32(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "import time, sagemaker\n",
    "\n",
    "role   = sagemaker.get_execution_role()\n",
    "sess   = sagemaker.Session()\n",
    "\n",
    "reward_est = HuggingFace(\n",
    "    entry_point         = \"train_reward.py\",\n",
    "    source_dir          = \"./\",          # has script + requirements.txt\n",
    "    role                = role,\n",
    "    instance_type       = \"ml.g5.12xlarge\",\n",
    "    instance_count      = 1,\n",
    "    transformers_version= \"4.49.0\",\n",
    "    pytorch_version     = \"2.5.1\",\n",
    "    py_version          = \"py311\",\n",
    "    environment = {\n",
    "        \"HF_EULA_ACCEPT\": \"true\",\n",
    "        \"HF_TOKEN\"      : \"\",     # 🔑 your token\n",
    "        \"BASE_ID\"       : \"meta-llama/Meta-Llama-3-8B\",  # or …-Instruct\n",
    "        \"TRAIN_FILE\"    : s3_rm\n",
    "    }\n",
    ")\n",
    "\n",
    "reward_est.fit(job_name=f\"rm-{int(time.time())}\")\n",
    "\n",
    "rm_uri = reward_est.model_data\n",
    "print(\"Reward model artefact:\", rm_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda85ed9-1416-4195-afa3-b1a1fd58fd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.11/site-packages (2.227.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.248.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting attrs<26,>=24 (from sagemaker)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting boto3<2.0,>=1.35.36 (from sagemaker)\n",
      "  Downloading boto3-1.39.11-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.110.3)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: graphene<4,>=3 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (3.3)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.21.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<3,>=2.2 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: packaging<25,>=23.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (24.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.2.2)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker) (3.11.0)\n",
      "Requirement already satisfied: protobuf<6.32,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.32.3)\n",
      "Collecting sagemaker-core<2.0.0,>=1.0.17 (from sagemaker)\n",
      "  Using cached sagemaker_core-1.0.46-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.66.5)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.26.19)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.30.6)\n",
      "Collecting botocore<1.40.0,>=1.39.11 (from boto3<2.0,>=1.35.36->sagemaker)\n",
      "  Downloading botocore-1.39.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.36->sagemaker) (1.0.1)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3<2.0,>=1.35.36->sagemaker)\n",
      "  Using cached s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4,>=3->sagemaker) (3.2.3)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4,>=3->sagemaker) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /opt/conda/lib/python3.11/site-packages (from graphene<4,>=3->sagemaker) (9.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.20.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.11/site-packages (from omegaconf<3,>=2.2->sagemaker) (4.9.3)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting platformdirs (from sagemaker)\n",
      "  Using cached platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (13.7.1)\n",
      "Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Using cached mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (2024.7.4)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker) (0.37.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker) (4.12.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Using cached pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.18.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.11/site-packages (from starlette<0.38.0,>=0.37.2->fastapi->sagemaker) (4.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Downloading sagemaker-2.248.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading boto3-1.39.11-py3-none-any.whl (139 kB)\n",
      "Using cached sagemaker_core-1.0.46-py3-none-any.whl (418 kB)\n",
      "Using cached platformdirs-4.3.8-py3-none-any.whl (18 kB)\n",
      "Downloading botocore-1.39.11-py3-none-any.whl (13.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, platformdirs, mock, attrs, pydantic, botocore, s3transfer, boto3, sagemaker-core, sagemaker\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.18.4\n",
      "    Uninstalling pydantic_core-2.18.4:\n",
      "      Successfully uninstalled pydantic_core-2.18.4\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 3.11.0\n",
      "    Uninstalling platformdirs-3.11.0:\n",
      "      Successfully uninstalled platformdirs-3.11.0\n",
      "  Attempting uninstall: mock\n",
      "    Found existing installation: mock 5.1.0\n",
      "    Uninstalling mock-5.1.0:\n",
      "      Successfully uninstalled mock-5.1.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.2.0\n",
      "    Uninstalling attrs-23.2.0:\n",
      "      Successfully uninstalled attrs-23.2.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.17\n",
      "    Uninstalling pydantic-1.10.17:\n",
      "      Successfully uninstalled pydantic-1.10.17\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.131\n",
      "    Uninstalling botocore-1.34.131:\n",
      "      Successfully uninstalled botocore-1.34.131\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.10.2\n",
      "    Uninstalling s3transfer-0.10.2:\n",
      "      Successfully uninstalled s3transfer-0.10.2\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.131\n",
      "    Uninstalling boto3-1.34.131:\n",
      "      Successfully uninstalled boto3-1.34.131\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.227.0\n",
      "    Uninstalling sagemaker-2.227.0:\n",
      "      Successfully uninstalled sagemaker-2.227.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires accelerate<0.22.0,>=0.21.0, which is not installed.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "autogluon-timeseries 1.1.1 requires accelerate<0.22.0,>=0.21.0, which is not installed.\n",
      "aiobotocore 2.13.2 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.39.11 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.1 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-features 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires transformers[sentencepiece]<4.41.0,>=4.38.0, but you have transformers 4.49.0 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires transformers[sentencepiece]<4.41.0,>=4.38.0, but you have transformers 4.49.0 which is incompatible.\n",
      "langchain-aws 0.1.16 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.39.11 which is incompatible.\n",
      "langchain-community 0.2.12 requires langchain<0.3.0,>=0.2.13, but you have langchain 0.2.5 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.2 which is incompatible.\n",
      "virtualenv 20.21.0 requires platformdirs<4,>=2.4, but you have platformdirs 4.3.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed attrs-25.3.0 boto3-1.39.11 botocore-1.39.11 mock-4.0.3 platformdirs-4.3.8 pydantic-2.7.3 pydantic-core-2.33.2 s3transfer-0.13.1 sagemaker-2.248.2 sagemaker-core-1.0.46 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "748f9965-bad7-4ea6-84d1-c2c585df9e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: rm-1752957473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-19 20:39:06 Starting - Starting the training job...\n",
      "2025-07-19 20:39:14 Pending - Training job waiting for capacity......\n",
      "2025-07-19 20:40:13 Pending - Preparing the instances for training...\n",
      "2025-07-19 20:40:57 Downloading - Downloading the training image........................\n",
      "2025-07-19 20:45:04 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mCUDA compat package should be installed for NVIDIA driver smaller than 550.144.03\u001b[0m\n",
      "\u001b[34mCurrent installed NVIDIA driver version is 550.163.01\u001b[0m\n",
      "\u001b[34mSkipping CUDA compat setup as newer NVIDIA driver is installed\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:42,876 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:42,913 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:42,922 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:42,924 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:47,281 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: trl>=0.8.9 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.15.2)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==1.9.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.29.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bitsandbytes>=0.42.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.45.5)\u001b[0m\n",
      "\u001b[34mCollecting s3fs<2025.0,>=2024.12.0 (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading s3fs-2024.12.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (7.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (2.5.1+cu124)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (0.5.3)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore<3.0.0,>=2.5.4 (from s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading aiobotocore-2.23.1-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec==2024.12.0.* in /opt/conda/lib/python3.11/site-packages (from s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (2024.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (3.11.18)\u001b[0m\n",
      "\u001b[34mCollecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.38.47,>=1.38.40 (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.38.46-py3-none-any.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0.0,>=6.0.0 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (6.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.17.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (2.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (0.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.20.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.38.47,>=1.38.40->aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (3.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from trl>=0.8.9->-r requirements.txt (line 2)) (13.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers>=4.46.0 in /opt/conda/lib/python3.11/site-packages (from trl>=0.8.9->-r requirements.txt (line 2)) (4.49.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft->-r requirements.txt (line 4)) (4.66.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (3.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (20.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (2.2.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (2.32.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (4.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (3.1.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 5)) (3.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 5)) (2025.1.31)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl>=0.8.9->-r requirements.txt (line 2)) (2024.11.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl>=0.8.9->-r requirements.txt (line 2)) (0.21.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (3.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2025.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl>=0.8.9->-r requirements.txt (line 2)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl>=0.8.9->-r requirements.txt (line 2)) (2.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl>=0.8.9->-r requirements.txt (line 2)) (0.1.2)\u001b[0m\n",
      "\u001b[34mDownloading accelerate-1.9.0-py3-none-any.whl (367 kB)\u001b[0m\n",
      "\u001b[34mDownloading s3fs-2024.12.0-py3-none-any.whl (30 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiobotocore-2.23.1-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34mDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.38.46-py3-none-any.whl (13.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.7/13.7 MB 161.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: aioitertools, botocore, aiobotocore, accelerate, s3fs\u001b[0m\n",
      "\u001b[34mAttempting uninstall: botocore\u001b[0m\n",
      "\u001b[34mFound existing installation: botocore 1.37.11\u001b[0m\n",
      "\u001b[34mUninstalling botocore-1.37.11:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled botocore-1.37.11\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 1.4.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-1.4.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-1.4.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: s3fs\u001b[0m\n",
      "\u001b[34mFound existing installation: s3fs 0.4.2\u001b[0m\n",
      "\u001b[34mUninstalling s3fs-0.4.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled s3fs-0.4.2\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mawscli 1.38.11 requires botocore==1.37.11, but you have botocore 1.38.46 which is incompatible.\u001b[0m\n",
      "\u001b[34mboto3 1.37.11 requires botocore<1.38.0,>=1.37.11, but you have botocore 1.38.46 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-1.9.0 aiobotocore-2.23.1 aioitertools-0.12.0 botocore-1.38.46 s3fs-2024.12.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:50,640 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:50,640 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:50,695 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:50,742 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:50,789 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:50,798 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"rm-1752957473\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-842747873802/rm-1752957473/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_reward\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_reward.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_reward.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_reward\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-842747873802/rm-1752957473/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.12xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"rm-1752957473\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-842747873802/rm-1752957473/source/sourcedir.tar.gz\",\"module_name\":\"train_reward\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_reward.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.11 train_reward.py\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:50,800 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-07-19 20:45:50,800 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mNote: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  25%|██▌       | 1/4 [00:04<00:13,  4.42s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 2/4 [00:08<00:08,  4.37s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.28s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [00:14<00:00,  3.31s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [00:14<00:00,  3.69s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.55s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.64s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.63s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.13s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.31s/it]\u001b[0m\n",
      "\u001b[34mSome weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/6.01M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 6.01M/6.01M [00:00<00:00, 72.9MB/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2822 examples [00:00, 174425.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/2822 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 98/2822 [00:00<00:02, 967.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 208/2822 [00:00<00:02, 1039.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█▏        | 320/2822 [00:00<00:02, 1070.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 431/2822 [00:00<00:02, 1080.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 590/2822 [00:00<00:02, 1065.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 701/2822 [00:00<00:01, 1075.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 816/2822 [00:00<00:01, 1093.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 927/2822 [00:00<00:01, 1096.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1056/2822 [00:01<00:02, 845.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████▏     | 1165/2822 [00:01<00:01, 902.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1277/2822 [00:01<00:01, 955.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1391/2822 [00:01<00:01, 1003.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1507/2822 [00:01<00:01, 1044.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1616/2822 [00:01<00:01, 1055.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████▏   | 1729/2822 [00:01<00:01, 1073.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 1893/2822 [00:01<00:00, 1080.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2053/2822 [00:02<00:00, 879.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2166/2822 [00:02<00:00, 931.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2276/2822 [00:02<00:00, 968.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2384/2822 [00:02<00:00, 994.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2497/2822 [00:02<00:00, 1028.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 2614/2822 [00:02<00:00, 1063.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 2775/2822 [00:02<00:00, 1063.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 2822/2822 [00:02<00:00, 983.88 examples/s]\u001b[0m\n",
      "\u001b[34mNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\u001b[0m\n",
      "\u001b[34mNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\u001b[0m\n",
      "\u001b[34m0%|          | 0/1056 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mYou're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34mYou're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m0%|          | 1/1056 [00:02<46:24,  2.64s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/1056 [00:04<40:35,  2.31s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/1056 [00:06<38:43,  2.21s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/1056 [00:08<38:14,  2.18s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 5/1056 [00:11<37:27,  2.14s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 6/1056 [00:13<37:22,  2.14s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 7/1056 [00:15<36:35,  2.09s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 8/1056 [00:17<36:43,  2.10s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 9/1056 [00:19<35:13,  2.02s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 10/1056 [00:21<35:42,  2.05s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 11/1056 [00:23<36:11,  2.08s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 12/1056 [00:25<36:33,  2.10s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 13/1056 [00:27<36:46,  2.12s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 14/1056 [00:29<36:45,  2.12s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 15/1056 [00:31<36:16,  2.09s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 16/1056 [00:33<35:33,  2.05s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 17/1056 [00:35<35:10,  2.03s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 18/1056 [00:37<35:30,  2.05s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 19/1056 [00:39<35:07,  2.03s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 20/1056 [00:41<35:22,  2.05s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 21/1056 [00:44<35:28,  2.06s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 22/1056 [00:46<35:31,  2.06s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 23/1056 [00:48<35:32,  2.06s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 24/1056 [00:50<36:39,  2.13s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 25/1056 [00:52<36:25,  2.12s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 26/1056 [00:54<35:41,  2.08s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 27/1056 [00:56<34:57,  2.04s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 28/1056 [00:58<34:44,  2.03s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 29/1056 [01:00<35:25,  2.07s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 30/1056 [01:02<36:20,  2.13s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 31/1056 [01:04<35:46,  2.09s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 32/1056 [01:06<35:27,  2.08s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 33/1056 [01:08<34:52,  2.05s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 34/1056 [01:10<34:52,  2.05s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 35/1056 [01:13<35:09,  2.07s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 36/1056 [01:15<34:54,  2.05s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 37/1056 [01:17<34:33,  2.04s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 38/1056 [01:19<35:02,  2.07s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 39/1056 [01:21<35:24,  2.09s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 40/1056 [01:23<35:33,  2.10s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 41/1056 [01:25<34:44,  2.05s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 42/1056 [01:27<35:07,  2.08s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 43/1056 [01:29<34:48,  2.06s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 44/1056 [01:31<34:32,  2.05s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 45/1056 [01:33<34:58,  2.08s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 46/1056 [01:35<35:18,  2.10s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 47/1056 [01:37<34:31,  2.05s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 48/1056 [01:40<35:05,  2.09s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 49/1056 [01:42<35:25,  2.11s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 50/1056 [01:44<34:30,  2.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 5081847234.56, 'grad_norm': nan, 'learning_rate': 1.9053030303030303e-05, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m5%|▍         | 50/1056 [01:44<34:30,  2.06s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 51/1056 [01:46<34:05,  2.04s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 52/1056 [01:48<34:03,  2.04s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 53/1056 [01:50<34:14,  2.05s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 54/1056 [01:52<34:14,  2.05s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 55/1056 [01:54<33:55,  2.03s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 56/1056 [01:56<34:26,  2.07s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 57/1056 [01:58<34:59,  2.10s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 58/1056 [02:00<34:14,  2.06s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 59/1056 [02:02<34:22,  2.07s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 60/1056 [02:04<33:39,  2.03s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 61/1056 [02:06<33:29,  2.02s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 62/1056 [02:08<33:27,  2.02s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 63/1056 [02:10<33:56,  2.05s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 64/1056 [02:12<33:48,  2.04s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 65/1056 [02:14<34:03,  2.06s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 66/1056 [02:16<34:07,  2.07s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 67/1056 [02:18<33:36,  2.04s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 68/1056 [02:20<33:47,  2.05s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 69/1056 [02:23<33:36,  2.04s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 70/1056 [02:25<33:51,  2.06s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 71/1056 [02:27<34:06,  2.08s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 72/1056 [02:29<34:52,  2.13s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 73/1056 [02:31<35:08,  2.15s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 74/1056 [02:33<34:36,  2.11s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 75/1056 [02:35<34:11,  2.09s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 76/1056 [02:37<34:13,  2.10s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 77/1056 [02:39<34:11,  2.10s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 78/1056 [02:41<33:24,  2.05s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 79/1056 [02:43<33:07,  2.03s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 80/1056 [02:45<33:26,  2.06s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 81/1056 [02:48<34:07,  2.10s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 82/1056 [02:50<34:18,  2.11s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 83/1056 [02:52<34:04,  2.10s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 84/1056 [02:54<33:31,  2.07s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 85/1056 [02:56<33:35,  2.08s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 86/1056 [02:58<33:42,  2.08s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 87/1056 [03:00<32:52,  2.04s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 88/1056 [03:02<32:47,  2.03s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 89/1056 [03:04<33:10,  2.06s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 90/1056 [03:06<33:30,  2.08s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 91/1056 [03:08<32:47,  2.04s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 92/1056 [03:10<33:06,  2.06s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 93/1056 [03:12<32:57,  2.05s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 94/1056 [03:15<33:36,  2.10s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 95/1056 [03:17<33:28,  2.09s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 96/1056 [03:19<33:09,  2.07s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 97/1056 [03:21<32:59,  2.06s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 98/1056 [03:23<33:56,  2.13s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 99/1056 [03:25<33:32,  2.10s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 100/1056 [03:27<32:32,  2.04s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.810606060606061e-05, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m9%|▉         | 100/1056 [03:27<32:32,  2.04s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 101/1056 [03:29<32:42,  2.06s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 102/1056 [03:31<32:53,  2.07s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 103/1056 [03:33<33:10,  2.09s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 104/1056 [03:35<33:21,  2.10s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 105/1056 [03:38<34:00,  2.15s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 106/1056 [03:40<33:54,  2.14s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 107/1056 [03:42<34:04,  2.15s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 108/1056 [03:44<33:56,  2.15s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 109/1056 [03:46<33:08,  2.10s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 110/1056 [03:48<33:00,  2.09s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 111/1056 [03:50<32:45,  2.08s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 112/1056 [03:52<33:08,  2.11s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 113/1056 [03:54<32:55,  2.09s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 114/1056 [03:57<32:57,  2.10s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 115/1056 [03:59<33:08,  2.11s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 116/1056 [04:01<33:01,  2.11s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 117/1056 [04:03<33:27,  2.14s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 118/1056 [04:05<33:12,  2.12s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 119/1056 [04:07<32:25,  2.08s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 120/1056 [04:09<32:45,  2.10s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 121/1056 [04:11<32:28,  2.08s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 122/1056 [04:14<33:16,  2.14s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 123/1056 [04:16<32:58,  2.12s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 124/1056 [04:18<32:55,  2.12s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 125/1056 [04:20<32:27,  2.09s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 126/1056 [04:22<32:02,  2.07s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 127/1056 [04:24<32:04,  2.07s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 128/1056 [04:26<32:37,  2.11s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 129/1056 [04:28<32:48,  2.12s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 130/1056 [04:30<32:10,  2.08s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 131/1056 [04:32<32:56,  2.14s/it]\u001b[0m\n",
      "\u001b[34m12%|█▎        | 132/1056 [04:35<32:55,  2.14s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 133/1056 [04:37<32:56,  2.14s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 134/1056 [04:39<32:53,  2.14s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 135/1056 [04:41<32:29,  2.12s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 136/1056 [04:43<31:55,  2.08s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 137/1056 [04:45<32:12,  2.10s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 138/1056 [04:47<32:26,  2.12s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 139/1056 [04:49<31:42,  2.07s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 140/1056 [04:51<31:17,  2.05s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 141/1056 [04:53<31:54,  2.09s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 142/1056 [04:56<32:02,  2.10s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 143/1056 [04:58<31:51,  2.09s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 144/1056 [05:00<31:31,  2.07s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 145/1056 [05:02<31:45,  2.09s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 146/1056 [05:04<31:51,  2.10s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 147/1056 [05:06<31:35,  2.09s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 148/1056 [05:08<32:15,  2.13s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 149/1056 [05:10<32:01,  2.12s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 150/1056 [05:12<32:04,  2.12s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.715909090909091e-05, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 150/1056 [05:12<32:04,  2.12s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 151/1056 [05:14<31:39,  2.10s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 152/1056 [05:17<31:59,  2.12s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 153/1056 [05:19<31:49,  2.11s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 154/1056 [05:21<32:00,  2.13s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 155/1056 [05:23<31:05,  2.07s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 156/1056 [05:25<32:03,  2.14s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 157/1056 [05:27<31:05,  2.08s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 158/1056 [05:29<31:29,  2.10s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 159/1056 [05:31<31:42,  2.12s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 160/1056 [05:34<31:41,  2.12s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 161/1056 [05:35<30:39,  2.06s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 162/1056 [05:37<30:18,  2.03s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 163/1056 [05:40<30:46,  2.07s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 164/1056 [05:42<31:05,  2.09s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 165/1056 [05:44<30:41,  2.07s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 166/1056 [05:46<30:53,  2.08s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 167/1056 [05:48<31:30,  2.13s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 168/1056 [05:50<31:32,  2.13s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 169/1056 [05:52<31:12,  2.11s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 170/1056 [05:54<30:47,  2.09s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 171/1056 [05:56<30:06,  2.04s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 172/1056 [05:58<30:07,  2.04s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 173/1056 [06:00<30:22,  2.06s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 174/1056 [06:02<30:17,  2.06s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 175/1056 [06:04<30:13,  2.06s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 176/1056 [06:07<30:36,  2.09s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 177/1056 [06:09<29:58,  2.05s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 178/1056 [06:11<29:47,  2.04s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 179/1056 [06:13<30:20,  2.08s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 180/1056 [06:15<30:20,  2.08s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 181/1056 [06:17<30:40,  2.10s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 182/1056 [06:19<30:55,  2.12s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 183/1056 [06:21<30:45,  2.11s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 184/1056 [06:24<31:30,  2.17s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 185/1056 [06:26<30:45,  2.12s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 186/1056 [06:28<30:51,  2.13s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 187/1056 [06:30<30:24,  2.10s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 188/1056 [06:32<30:28,  2.11s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 189/1056 [06:34<30:37,  2.12s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 190/1056 [06:36<30:15,  2.10s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 191/1056 [06:38<29:39,  2.06s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 192/1056 [06:40<29:32,  2.05s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 193/1056 [06:42<29:26,  2.05s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 194/1056 [06:44<30:03,  2.09s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 195/1056 [06:46<29:46,  2.07s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 196/1056 [06:48<29:43,  2.07s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 197/1056 [06:51<29:47,  2.08s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 198/1056 [06:53<29:49,  2.09s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 199/1056 [06:55<29:30,  2.07s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 200/1056 [06:57<29:22,  2.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.6212121212121212e-05, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 200/1056 [06:57<29:22,  2.06s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 201/1056 [06:59<29:04,  2.04s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 202/1056 [07:01<29:11,  2.05s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 203/1056 [07:03<29:01,  2.04s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 204/1056 [07:05<28:51,  2.03s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 205/1056 [07:07<29:12,  2.06s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 206/1056 [07:09<29:39,  2.09s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 207/1056 [07:11<29:24,  2.08s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 208/1056 [07:13<29:52,  2.11s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 209/1056 [07:15<29:51,  2.11s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 210/1056 [07:17<29:36,  2.10s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 211/1056 [07:20<29:27,  2.09s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 212/1056 [07:22<28:59,  2.06s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 213/1056 [07:24<28:51,  2.05s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 214/1056 [07:26<29:31,  2.10s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 215/1056 [07:28<29:49,  2.13s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 216/1056 [07:30<29:59,  2.14s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 217/1056 [07:32<29:40,  2.12s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 218/1056 [07:34<29:33,  2.12s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 219/1056 [07:36<29:20,  2.10s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 220/1056 [07:39<29:19,  2.10s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 221/1056 [07:41<29:27,  2.12s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 222/1056 [07:43<28:52,  2.08s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 223/1056 [07:45<28:55,  2.08s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 224/1056 [07:47<28:39,  2.07s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 225/1056 [07:49<29:11,  2.11s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 226/1056 [07:51<29:13,  2.11s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 227/1056 [07:53<29:11,  2.11s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 228/1056 [07:55<29:08,  2.11s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 229/1056 [07:57<28:16,  2.05s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 230/1056 [07:59<27:49,  2.02s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 231/1056 [08:01<27:55,  2.03s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 232/1056 [08:03<27:43,  2.02s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 233/1056 [08:05<27:59,  2.04s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 234/1056 [08:07<27:33,  2.01s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 235/1056 [08:09<27:23,  2.00s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 236/1056 [08:11<27:16,  2.00s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 237/1056 [08:13<27:16,  2.00s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 238/1056 [08:15<27:16,  2.00s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 239/1056 [08:17<27:24,  2.01s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 240/1056 [08:19<27:40,  2.03s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 241/1056 [08:22<28:26,  2.09s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 242/1056 [08:24<28:03,  2.07s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 243/1056 [08:26<27:40,  2.04s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 244/1056 [08:28<27:58,  2.07s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 245/1056 [08:30<27:49,  2.06s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 246/1056 [08:32<27:58,  2.07s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 247/1056 [08:34<28:00,  2.08s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 248/1056 [08:36<28:19,  2.10s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 249/1056 [08:38<27:56,  2.08s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 250/1056 [08:40<27:54,  2.08s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.5265151515151517e-05, 'epoch': 0.71}\u001b[0m\n",
      "\u001b[34m24%|██▎       | 250/1056 [08:40<27:54,  2.08s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 251/1056 [08:42<27:35,  2.06s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 252/1056 [08:44<26:42,  1.99s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 253/1056 [08:46<26:53,  2.01s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 254/1056 [08:48<27:24,  2.05s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 255/1056 [08:50<27:33,  2.06s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 256/1056 [08:52<27:27,  2.06s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 257/1056 [08:55<27:42,  2.08s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 258/1056 [08:57<27:26,  2.06s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 259/1056 [08:59<27:32,  2.07s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 260/1056 [09:01<27:42,  2.09s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 261/1056 [09:03<27:34,  2.08s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 262/1056 [09:05<27:36,  2.09s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 263/1056 [09:07<26:53,  2.03s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 264/1056 [09:09<26:48,  2.03s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 265/1056 [09:11<26:55,  2.04s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 266/1056 [09:13<27:02,  2.05s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 267/1056 [09:15<26:46,  2.04s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 268/1056 [09:17<26:57,  2.05s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 269/1056 [09:19<27:02,  2.06s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 270/1056 [09:21<27:08,  2.07s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 271/1056 [09:23<27:07,  2.07s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 272/1056 [09:25<27:01,  2.07s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 273/1056 [09:27<27:02,  2.07s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 274/1056 [09:30<26:48,  2.06s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 275/1056 [09:32<26:33,  2.04s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 276/1056 [09:34<26:33,  2.04s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 277/1056 [09:36<26:27,  2.04s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 278/1056 [09:38<26:50,  2.07s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 279/1056 [09:40<26:55,  2.08s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 280/1056 [09:42<27:03,  2.09s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 281/1056 [09:44<26:53,  2.08s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 282/1056 [09:46<27:29,  2.13s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 283/1056 [09:48<27:19,  2.12s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 284/1056 [09:51<27:22,  2.13s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 285/1056 [09:53<27:24,  2.13s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 286/1056 [09:55<27:24,  2.14s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 287/1056 [09:57<26:46,  2.09s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 288/1056 [09:59<26:58,  2.11s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 289/1056 [10:01<26:32,  2.08s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 290/1056 [10:03<26:43,  2.09s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 291/1056 [10:05<26:24,  2.07s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 292/1056 [10:07<26:05,  2.05s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 293/1056 [10:09<26:32,  2.09s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 294/1056 [10:11<26:39,  2.10s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 295/1056 [10:13<26:32,  2.09s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 296/1056 [10:16<26:33,  2.10s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 297/1056 [10:18<26:08,  2.07s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 298/1056 [10:20<26:24,  2.09s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 299/1056 [10:22<26:11,  2.08s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 300/1056 [10:24<26:12,  2.08s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.431818181818182e-05, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 300/1056 [10:24<26:12,  2.08s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 301/1056 [10:26<26:23,  2.10s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 302/1056 [10:28<25:40,  2.04s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 303/1056 [10:30<25:38,  2.04s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 304/1056 [10:32<25:18,  2.02s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 305/1056 [10:34<25:26,  2.03s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 306/1056 [10:36<25:39,  2.05s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 307/1056 [10:38<25:48,  2.07s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 308/1056 [10:40<25:38,  2.06s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 309/1056 [10:42<25:32,  2.05s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 310/1056 [10:44<25:39,  2.06s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 311/1056 [10:46<25:51,  2.08s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 312/1056 [10:48<25:38,  2.07s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 313/1056 [10:51<25:47,  2.08s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 314/1056 [10:53<25:42,  2.08s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 315/1056 [10:55<25:47,  2.09s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 316/1056 [10:57<25:51,  2.10s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 317/1056 [10:59<25:13,  2.05s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 318/1056 [11:01<25:05,  2.04s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 319/1056 [11:03<25:35,  2.08s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 320/1056 [11:05<25:23,  2.07s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 321/1056 [11:07<25:22,  2.07s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 322/1056 [11:09<26:12,  2.14s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 323/1056 [11:12<26:17,  2.15s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 324/1056 [11:14<25:57,  2.13s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 325/1056 [11:16<25:50,  2.12s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 326/1056 [11:18<25:35,  2.10s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 327/1056 [11:20<26:17,  2.16s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 328/1056 [11:22<25:26,  2.10s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 329/1056 [11:24<25:22,  2.09s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 330/1056 [11:26<25:38,  2.12s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 331/1056 [11:28<24:51,  2.06s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 332/1056 [11:30<25:16,  2.09s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 333/1056 [11:33<25:03,  2.08s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 334/1056 [11:34<24:17,  2.02s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 335/1056 [11:36<24:24,  2.03s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 336/1056 [11:39<25:20,  2.11s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 337/1056 [11:41<25:23,  2.12s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 338/1056 [11:43<25:41,  2.15s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 339/1056 [11:45<25:39,  2.15s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 340/1056 [11:47<25:11,  2.11s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 341/1056 [11:49<24:53,  2.09s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 342/1056 [11:51<24:59,  2.10s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 343/1056 [11:53<24:42,  2.08s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 344/1056 [11:55<23:59,  2.02s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 345/1056 [11:57<23:42,  2.00s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 346/1056 [11:59<23:46,  2.01s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 347/1056 [12:01<23:42,  2.01s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 348/1056 [12:03<23:45,  2.01s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 349/1056 [12:05<24:01,  2.04s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 350/1056 [12:08<24:31,  2.08s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.3371212121212122e-05, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 350/1056 [12:08<24:31,  2.08s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 351/1056 [12:10<25:21,  2.16s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 352/1056 [12:12<24:37,  2.10s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 353/1056 [12:13<22:35,  1.93s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 354/1056 [12:16<23:08,  1.98s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 355/1056 [12:18<23:44,  2.03s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 356/1056 [12:20<24:20,  2.09s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 357/1056 [12:22<23:48,  2.04s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 358/1056 [12:24<23:45,  2.04s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 359/1056 [12:26<24:20,  2.09s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 360/1056 [12:28<24:37,  2.12s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 361/1056 [12:30<24:13,  2.09s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 362/1056 [12:32<24:07,  2.09s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 363/1056 [12:34<23:57,  2.07s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 364/1056 [12:36<23:38,  2.05s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 365/1056 [12:39<24:13,  2.10s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 366/1056 [12:41<23:57,  2.08s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 367/1056 [12:43<23:39,  2.06s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 368/1056 [12:45<23:20,  2.04s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 369/1056 [12:47<23:21,  2.04s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 370/1056 [12:49<23:10,  2.03s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 371/1056 [12:51<23:19,  2.04s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 372/1056 [12:53<23:30,  2.06s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 373/1056 [12:55<23:28,  2.06s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 374/1056 [12:57<23:32,  2.07s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 375/1056 [12:59<23:36,  2.08s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 376/1056 [13:01<23:41,  2.09s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 377/1056 [13:03<23:28,  2.07s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 378/1056 [13:05<22:55,  2.03s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 379/1056 [13:07<23:00,  2.04s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 380/1056 [13:09<22:45,  2.02s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 381/1056 [13:11<23:01,  2.05s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 382/1056 [13:14<23:21,  2.08s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 383/1056 [13:16<23:43,  2.12s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 384/1056 [13:18<23:26,  2.09s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 385/1056 [13:20<23:39,  2.12s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 386/1056 [13:22<23:44,  2.13s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 387/1056 [13:24<23:45,  2.13s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 388/1056 [13:26<23:39,  2.12s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 389/1056 [13:29<23:51,  2.15s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 390/1056 [13:31<23:49,  2.15s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 391/1056 [13:33<23:47,  2.15s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 392/1056 [13:35<23:29,  2.12s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 393/1056 [13:37<23:19,  2.11s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 394/1056 [13:39<23:13,  2.10s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 395/1056 [13:41<23:03,  2.09s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 396/1056 [13:43<23:14,  2.11s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 397/1056 [13:45<23:09,  2.11s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 398/1056 [13:48<23:19,  2.13s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 399/1056 [13:50<23:05,  2.11s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 400/1056 [13:52<23:07,  2.12s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.2424242424242425e-05, 'epoch': 1.13}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 400/1056 [13:52<23:07,  2.12s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 401/1056 [13:54<22:57,  2.10s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 402/1056 [13:56<22:57,  2.11s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 403/1056 [13:58<22:40,  2.08s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 404/1056 [14:00<22:35,  2.08s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 405/1056 [14:02<22:24,  2.06s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 406/1056 [14:04<22:17,  2.06s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 407/1056 [14:06<22:13,  2.06s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 408/1056 [14:08<22:12,  2.06s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 409/1056 [14:10<22:25,  2.08s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 410/1056 [14:12<22:18,  2.07s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 411/1056 [14:15<22:17,  2.07s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 412/1056 [14:17<22:21,  2.08s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 413/1056 [14:19<22:29,  2.10s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 414/1056 [14:21<22:03,  2.06s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 415/1056 [14:23<22:08,  2.07s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 416/1056 [14:25<22:24,  2.10s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 417/1056 [14:27<22:52,  2.15s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 418/1056 [14:29<22:56,  2.16s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 419/1056 [14:32<23:06,  2.18s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 420/1056 [14:34<22:43,  2.14s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 421/1056 [14:36<22:31,  2.13s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 422/1056 [14:38<22:25,  2.12s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 423/1056 [14:40<22:17,  2.11s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 424/1056 [14:42<21:53,  2.08s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 425/1056 [14:44<21:24,  2.04s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 426/1056 [14:46<21:21,  2.03s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 427/1056 [14:48<21:21,  2.04s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 428/1056 [14:50<21:08,  2.02s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 429/1056 [14:52<21:23,  2.05s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 430/1056 [14:54<21:26,  2.06s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 431/1056 [14:56<21:42,  2.08s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 432/1056 [14:58<21:39,  2.08s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 433/1056 [15:01<22:07,  2.13s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 434/1056 [15:03<22:22,  2.16s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 435/1056 [15:05<21:57,  2.12s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 436/1056 [15:07<21:38,  2.09s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 437/1056 [15:09<21:37,  2.10s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 438/1056 [15:11<21:57,  2.13s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 439/1056 [15:13<21:36,  2.10s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 440/1056 [15:15<21:39,  2.11s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 441/1056 [15:18<21:55,  2.14s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 442/1056 [15:20<21:42,  2.12s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 443/1056 [15:22<21:29,  2.10s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 444/1056 [15:24<21:43,  2.13s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 445/1056 [15:26<21:23,  2.10s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 446/1056 [15:28<20:55,  2.06s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 447/1056 [15:30<21:02,  2.07s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 448/1056 [15:32<21:10,  2.09s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 449/1056 [15:35<21:55,  2.17s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 450/1056 [15:37<21:22,  2.12s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.1477272727272729e-05, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 450/1056 [15:37<21:22,  2.12s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 451/1056 [15:39<21:13,  2.11s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 452/1056 [15:41<21:07,  2.10s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 453/1056 [15:43<20:42,  2.06s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 454/1056 [15:45<20:55,  2.09s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 455/1056 [15:47<21:01,  2.10s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 456/1056 [15:49<20:31,  2.05s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 457/1056 [15:51<20:33,  2.06s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 458/1056 [15:53<20:41,  2.08s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 459/1056 [15:55<21:06,  2.12s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 460/1056 [15:57<20:46,  2.09s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 461/1056 [16:00<20:57,  2.11s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 462/1056 [16:02<21:02,  2.13s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 463/1056 [16:04<21:25,  2.17s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 464/1056 [16:06<21:06,  2.14s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 465/1056 [16:08<20:54,  2.12s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 466/1056 [16:10<20:50,  2.12s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 467/1056 [16:12<20:33,  2.09s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 468/1056 [16:14<20:11,  2.06s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 469/1056 [16:16<20:05,  2.05s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 470/1056 [16:18<20:06,  2.06s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 471/1056 [16:20<20:12,  2.07s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 472/1056 [16:22<19:54,  2.05s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 473/1056 [16:24<19:39,  2.02s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 474/1056 [16:26<19:43,  2.03s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 475/1056 [16:29<20:02,  2.07s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 476/1056 [16:31<19:59,  2.07s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 477/1056 [16:33<19:58,  2.07s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 478/1056 [16:35<20:20,  2.11s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 479/1056 [16:37<20:38,  2.15s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 480/1056 [16:39<20:26,  2.13s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 481/1056 [16:41<20:34,  2.15s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 482/1056 [16:43<20:00,  2.09s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 483/1056 [16:46<20:02,  2.10s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 484/1056 [16:48<19:38,  2.06s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 485/1056 [16:50<19:27,  2.04s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 486/1056 [16:51<19:10,  2.02s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 487/1056 [16:54<19:29,  2.06s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 488/1056 [16:56<19:46,  2.09s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 489/1056 [16:58<19:48,  2.10s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 490/1056 [17:00<19:22,  2.05s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 491/1056 [17:02<19:10,  2.04s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 492/1056 [17:04<19:23,  2.06s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 493/1056 [17:06<19:24,  2.07s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 494/1056 [17:08<19:08,  2.04s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 495/1056 [17:10<19:26,  2.08s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 496/1056 [17:12<19:32,  2.09s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 497/1056 [17:14<19:03,  2.05s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 498/1056 [17:16<19:08,  2.06s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 499/1056 [17:18<19:08,  2.06s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 500/1056 [17:21<19:08,  2.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.053030303030303e-05, 'epoch': 1.42}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 500/1056 [17:21<19:08,  2.07s/it]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m47%|████▋     | 501/1056 [17:23<20:32,  2.22s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 502/1056 [17:25<20:09,  2.18s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 503/1056 [17:27<19:36,  2.13s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 504/1056 [17:29<19:05,  2.08s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 505/1056 [17:31<19:27,  2.12s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 506/1056 [17:33<19:28,  2.12s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 507/1056 [17:36<19:46,  2.16s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 508/1056 [17:38<19:43,  2.16s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 509/1056 [17:40<19:46,  2.17s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 510/1056 [17:42<19:27,  2.14s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 511/1056 [17:44<19:33,  2.15s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 512/1056 [17:46<19:12,  2.12s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 513/1056 [17:48<18:56,  2.09s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 514/1056 [17:50<18:39,  2.07s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 515/1056 [17:53<18:48,  2.09s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 516/1056 [17:55<18:27,  2.05s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 517/1056 [17:57<18:34,  2.07s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 518/1056 [17:59<18:28,  2.06s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 519/1056 [18:01<18:16,  2.04s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 520/1056 [18:03<18:29,  2.07s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 521/1056 [18:05<18:02,  2.02s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 522/1056 [18:07<17:56,  2.02s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 523/1056 [18:09<17:44,  2.00s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 524/1056 [18:11<17:55,  2.02s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 525/1056 [18:13<18:10,  2.05s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 526/1056 [18:15<18:33,  2.10s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 527/1056 [18:17<18:44,  2.13s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 528/1056 [18:19<18:40,  2.12s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 529/1056 [18:22<18:39,  2.12s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 530/1056 [18:24<18:43,  2.14s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 531/1056 [18:26<18:29,  2.11s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 532/1056 [18:28<18:28,  2.11s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 533/1056 [18:30<18:21,  2.11s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 534/1056 [18:32<18:16,  2.10s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 535/1056 [18:34<18:06,  2.09s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 536/1056 [18:36<18:08,  2.09s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 537/1056 [18:38<17:54,  2.07s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 538/1056 [18:40<18:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 539/1056 [18:42<17:42,  2.06s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 540/1056 [18:44<17:33,  2.04s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 541/1056 [18:46<17:34,  2.05s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 542/1056 [18:48<17:23,  2.03s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 543/1056 [18:51<17:37,  2.06s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 544/1056 [18:53<17:31,  2.05s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 545/1056 [18:55<17:12,  2.02s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 546/1056 [18:56<17:02,  2.00s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 547/1056 [18:59<17:10,  2.02s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 548/1056 [19:01<17:06,  2.02s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 549/1056 [19:03<17:11,  2.03s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 550/1056 [19:05<17:00,  2.02s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.583333333333335e-06, 'epoch': 1.56}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 550/1056 [19:05<17:00,  2.02s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 551/1056 [19:07<17:23,  2.07s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 552/1056 [19:09<17:32,  2.09s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 553/1056 [19:11<17:08,  2.04s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 554/1056 [19:13<16:48,  2.01s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 555/1056 [19:15<16:38,  1.99s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 556/1056 [19:17<16:36,  1.99s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 557/1056 [19:19<16:40,  2.01s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 558/1056 [19:21<17:06,  2.06s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 559/1056 [19:23<16:52,  2.04s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 560/1056 [19:25<16:49,  2.04s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 561/1056 [19:27<17:01,  2.06s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 562/1056 [19:29<17:13,  2.09s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 563/1056 [19:31<17:06,  2.08s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 564/1056 [19:33<17:10,  2.09s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 565/1056 [19:36<17:22,  2.12s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 566/1056 [19:38<16:59,  2.08s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 567/1056 [19:40<16:43,  2.05s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 568/1056 [19:42<16:38,  2.05s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 569/1056 [19:44<16:33,  2.04s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 570/1056 [19:46<16:15,  2.01s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 571/1056 [19:48<16:22,  2.03s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 572/1056 [19:50<16:16,  2.02s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 573/1056 [19:52<16:07,  2.00s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 574/1056 [19:54<16:04,  2.00s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 575/1056 [19:56<15:50,  1.98s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 576/1056 [19:58<16:14,  2.03s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 577/1056 [20:00<16:26,  2.06s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 578/1056 [20:02<16:47,  2.11s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 579/1056 [20:04<16:53,  2.12s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 580/1056 [20:06<16:49,  2.12s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 581/1056 [20:08<16:41,  2.11s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 582/1056 [20:11<16:49,  2.13s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 583/1056 [20:13<16:51,  2.14s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 584/1056 [20:15<16:22,  2.08s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 585/1056 [20:17<16:30,  2.10s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 586/1056 [20:19<16:27,  2.10s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 587/1056 [20:21<16:24,  2.10s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 588/1056 [20:23<16:10,  2.07s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 589/1056 [20:25<16:06,  2.07s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 590/1056 [20:27<16:02,  2.07s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 591/1056 [20:29<15:52,  2.05s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 592/1056 [20:31<15:50,  2.05s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 593/1056 [20:33<15:38,  2.03s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 594/1056 [20:35<15:49,  2.05s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 595/1056 [20:37<15:57,  2.08s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 596/1056 [20:39<15:37,  2.04s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 597/1056 [20:42<16:07,  2.11s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 598/1056 [20:44<16:04,  2.10s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 599/1056 [20:46<15:56,  2.09s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 600/1056 [20:48<15:47,  2.08s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.636363636363637e-06, 'epoch': 1.7}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 600/1056 [20:48<15:47,  2.08s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 601/1056 [20:50<15:30,  2.05s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 602/1056 [20:52<15:30,  2.05s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 603/1056 [20:54<15:34,  2.06s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 604/1056 [20:56<15:38,  2.08s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 605/1056 [20:58<15:39,  2.08s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 606/1056 [21:00<15:32,  2.07s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 607/1056 [21:02<15:55,  2.13s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 608/1056 [21:04<15:20,  2.05s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 609/1056 [21:06<14:59,  2.01s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 610/1056 [21:08<15:03,  2.02s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 611/1056 [21:11<15:19,  2.07s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 612/1056 [21:12<14:53,  2.01s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 613/1056 [21:14<14:53,  2.02s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 614/1056 [21:16<14:55,  2.03s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 615/1056 [21:19<15:21,  2.09s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 616/1056 [21:21<15:21,  2.09s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 617/1056 [21:23<15:28,  2.12s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 618/1056 [21:25<15:42,  2.15s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 619/1056 [21:27<15:31,  2.13s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 620/1056 [21:29<15:07,  2.08s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 621/1056 [21:31<15:15,  2.11s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 622/1056 [21:33<15:10,  2.10s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 623/1056 [21:36<15:04,  2.09s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 624/1056 [21:38<15:14,  2.12s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 625/1056 [21:40<15:04,  2.10s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 626/1056 [21:42<15:02,  2.10s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 627/1056 [21:44<15:00,  2.10s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 628/1056 [21:46<14:55,  2.09s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 629/1056 [21:48<14:58,  2.10s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 630/1056 [21:50<15:03,  2.12s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 631/1056 [21:52<14:58,  2.11s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 632/1056 [21:54<14:38,  2.07s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 633/1056 [21:56<14:18,  2.03s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 634/1056 [21:58<14:22,  2.04s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 635/1056 [22:01<14:25,  2.06s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 636/1056 [22:03<14:23,  2.06s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 637/1056 [22:05<14:10,  2.03s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 638/1056 [22:07<14:10,  2.03s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 639/1056 [22:09<14:23,  2.07s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 640/1056 [22:11<14:19,  2.07s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 641/1056 [22:13<14:09,  2.05s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 642/1056 [22:15<14:21,  2.08s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 643/1056 [22:17<14:32,  2.11s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 644/1056 [22:19<14:19,  2.09s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 645/1056 [22:21<14:28,  2.11s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 646/1056 [22:23<14:28,  2.12s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 647/1056 [22:26<14:19,  2.10s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 648/1056 [22:27<13:51,  2.04s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 649/1056 [22:30<14:13,  2.10s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 650/1056 [22:32<13:53,  2.05s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.68939393939394e-06, 'epoch': 1.84}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 650/1056 [22:32<13:53,  2.05s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 651/1056 [22:34<13:49,  2.05s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 652/1056 [22:36<14:04,  2.09s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 653/1056 [22:38<14:13,  2.12s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 654/1056 [22:40<13:36,  2.03s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 655/1056 [22:42<13:44,  2.06s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 656/1056 [22:44<13:37,  2.04s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 657/1056 [22:46<13:48,  2.08s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 658/1056 [22:48<13:35,  2.05s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 659/1056 [22:50<13:33,  2.05s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▎   | 660/1056 [22:52<13:42,  2.08s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 661/1056 [22:54<13:44,  2.09s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 662/1056 [22:56<13:32,  2.06s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 663/1056 [22:58<13:21,  2.04s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 664/1056 [23:01<13:25,  2.05s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 665/1056 [23:03<13:24,  2.06s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 666/1056 [23:05<13:16,  2.04s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 667/1056 [23:07<13:16,  2.05s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 668/1056 [23:09<13:06,  2.03s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 669/1056 [23:11<13:15,  2.06s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 670/1056 [23:13<13:09,  2.05s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 671/1056 [23:15<13:11,  2.06s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 672/1056 [23:17<13:18,  2.08s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 673/1056 [23:19<13:23,  2.10s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 674/1056 [23:21<13:21,  2.10s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 675/1056 [23:23<13:26,  2.12s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 676/1056 [23:26<13:29,  2.13s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 677/1056 [23:28<13:16,  2.10s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 678/1056 [23:30<13:18,  2.11s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 679/1056 [23:32<13:23,  2.13s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 680/1056 [23:34<13:28,  2.15s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 681/1056 [23:36<13:17,  2.13s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 682/1056 [23:38<13:04,  2.10s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 683/1056 [23:40<12:56,  2.08s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 684/1056 [23:42<13:01,  2.10s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 685/1056 [23:45<13:09,  2.13s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 686/1056 [23:47<13:00,  2.11s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 687/1056 [23:49<12:57,  2.11s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 688/1056 [23:51<13:02,  2.13s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 689/1056 [23:53<12:54,  2.11s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 690/1056 [23:55<12:50,  2.10s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 691/1056 [23:57<12:47,  2.10s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 692/1056 [23:59<12:39,  2.09s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 693/1056 [24:01<12:26,  2.06s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 694/1056 [24:03<12:16,  2.03s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 695/1056 [24:05<12:15,  2.04s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 696/1056 [24:07<12:06,  2.02s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 697/1056 [24:09<12:01,  2.01s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 698/1056 [24:11<12:02,  2.02s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 699/1056 [24:13<12:23,  2.08s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 700/1056 [24:15<12:07,  2.04s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 6.742424242424243e-06, 'epoch': 1.98}\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 700/1056 [24:15<12:07,  2.04s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 701/1056 [24:18<12:26,  2.10s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 702/1056 [24:20<12:28,  2.11s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 703/1056 [24:22<12:22,  2.10s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 704/1056 [24:24<12:11,  2.08s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 705/1056 [24:26<12:03,  2.06s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 706/1056 [24:27<11:00,  1.89s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 707/1056 [24:29<11:11,  1.93s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 708/1056 [24:31<11:22,  1.96s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 709/1056 [24:34<11:37,  2.01s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 710/1056 [24:36<11:47,  2.05s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 711/1056 [24:38<11:52,  2.06s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 712/1056 [24:40<12:05,  2.11s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 713/1056 [24:42<11:57,  2.09s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 714/1056 [24:44<11:55,  2.09s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 715/1056 [24:46<12:11,  2.15s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 716/1056 [24:48<11:54,  2.10s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 717/1056 [24:51<11:56,  2.11s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 718/1056 [24:52<11:29,  2.04s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 719/1056 [24:55<11:42,  2.08s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 720/1056 [24:57<11:45,  2.10s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 721/1056 [24:59<11:29,  2.06s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 722/1056 [25:01<11:24,  2.05s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 723/1056 [25:03<11:22,  2.05s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 724/1056 [25:05<11:25,  2.06s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 725/1056 [25:07<11:27,  2.08s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 726/1056 [25:09<11:31,  2.10s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 727/1056 [25:11<11:18,  2.06s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 728/1056 [25:13<11:15,  2.06s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 729/1056 [25:15<11:12,  2.06s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 730/1056 [25:17<11:15,  2.07s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 731/1056 [25:19<11:19,  2.09s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 732/1056 [25:22<11:16,  2.09s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 733/1056 [25:24<11:15,  2.09s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 734/1056 [25:26<10:53,  2.03s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 735/1056 [25:27<10:40,  2.00s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 736/1056 [25:29<10:40,  2.00s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 737/1056 [25:32<10:50,  2.04s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 738/1056 [25:34<10:58,  2.07s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 739/1056 [25:36<10:54,  2.06s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 740/1056 [25:38<10:50,  2.06s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 741/1056 [25:40<10:54,  2.08s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 742/1056 [25:42<11:07,  2.13s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 743/1056 [25:44<11:01,  2.11s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 744/1056 [25:46<10:52,  2.09s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 745/1056 [25:48<10:41,  2.06s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 746/1056 [25:51<10:48,  2.09s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 747/1056 [25:53<10:43,  2.08s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 748/1056 [25:55<10:38,  2.07s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 749/1056 [25:57<10:39,  2.08s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 750/1056 [25:59<10:38,  2.09s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.795454545454546e-06, 'epoch': 2.12}\u001b[0m\n",
      "\u001b[34m71%|███████   | 750/1056 [25:59<10:38,  2.09s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 751/1056 [26:01<10:49,  2.13s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 752/1056 [26:03<10:46,  2.13s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 753/1056 [26:05<10:45,  2.13s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 754/1056 [26:07<10:26,  2.08s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 755/1056 [26:09<10:30,  2.09s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 756/1056 [26:11<10:27,  2.09s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 757/1056 [26:14<10:26,  2.09s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 758/1056 [26:16<10:21,  2.09s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 759/1056 [26:18<10:20,  2.09s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 760/1056 [26:20<10:32,  2.14s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 761/1056 [26:22<10:28,  2.13s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 762/1056 [26:24<10:11,  2.08s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 763/1056 [26:26<10:15,  2.10s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 764/1056 [26:28<10:03,  2.07s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 765/1056 [26:30<09:46,  2.01s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 766/1056 [26:32<09:45,  2.02s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 767/1056 [26:34<09:40,  2.01s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 768/1056 [26:36<09:31,  1.98s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 769/1056 [26:38<09:44,  2.04s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 770/1056 [26:40<09:40,  2.03s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 771/1056 [26:42<09:35,  2.02s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 772/1056 [26:44<09:29,  2.00s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 773/1056 [26:46<09:35,  2.03s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 774/1056 [26:48<09:34,  2.04s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 775/1056 [26:50<09:44,  2.08s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 776/1056 [26:53<09:47,  2.10s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 777/1056 [26:55<09:36,  2.07s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 778/1056 [26:57<09:35,  2.07s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 779/1056 [26:59<09:43,  2.11s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 780/1056 [27:01<09:40,  2.10s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 781/1056 [27:03<09:31,  2.08s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 782/1056 [27:05<09:41,  2.12s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 783/1056 [27:07<09:25,  2.07s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 784/1056 [27:09<09:33,  2.11s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 785/1056 [27:12<09:32,  2.11s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 786/1056 [27:14<09:25,  2.10s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 787/1056 [27:16<09:31,  2.12s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 788/1056 [27:18<09:32,  2.14s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 789/1056 [27:20<09:34,  2.15s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 790/1056 [27:22<09:31,  2.15s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 791/1056 [27:24<09:14,  2.09s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 792/1056 [27:26<09:10,  2.09s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 793/1056 [27:28<09:10,  2.09s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 794/1056 [27:30<09:01,  2.07s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 795/1056 [27:32<08:52,  2.04s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 796/1056 [27:34<08:48,  2.03s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 797/1056 [27:36<08:39,  2.01s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 798/1056 [27:38<08:46,  2.04s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 799/1056 [27:40<08:37,  2.02s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 800/1056 [27:43<08:48,  2.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.848484848484849e-06, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 800/1056 [27:43<08:48,  2.06s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 801/1056 [27:45<08:40,  2.04s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 802/1056 [27:47<08:36,  2.03s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 803/1056 [27:49<08:29,  2.02s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 804/1056 [27:51<08:32,  2.04s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 805/1056 [27:53<08:34,  2.05s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 806/1056 [27:55<08:35,  2.06s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 807/1056 [27:57<08:39,  2.09s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 808/1056 [27:59<08:35,  2.08s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 809/1056 [28:01<08:42,  2.11s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 810/1056 [28:03<08:29,  2.07s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 811/1056 [28:05<08:21,  2.05s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 812/1056 [28:07<08:25,  2.07s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 813/1056 [28:09<08:13,  2.03s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 814/1056 [28:11<08:12,  2.04s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 815/1056 [28:13<08:11,  2.04s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 816/1056 [28:15<08:08,  2.04s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 817/1056 [28:18<08:16,  2.08s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 818/1056 [28:20<08:17,  2.09s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 819/1056 [28:22<08:10,  2.07s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 820/1056 [28:24<08:17,  2.11s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 821/1056 [28:26<08:14,  2.11s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 822/1056 [28:28<08:14,  2.11s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 823/1056 [28:30<08:03,  2.08s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 824/1056 [28:32<07:57,  2.06s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 825/1056 [28:34<07:59,  2.08s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 826/1056 [28:36<08:08,  2.12s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 827/1056 [28:39<08:09,  2.14s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 828/1056 [28:41<08:07,  2.14s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 829/1056 [28:43<07:53,  2.08s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 830/1056 [28:45<07:51,  2.09s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 831/1056 [28:47<07:43,  2.06s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 832/1056 [28:49<07:42,  2.06s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 833/1056 [28:51<07:40,  2.07s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 834/1056 [28:53<07:23,  2.00s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 835/1056 [28:55<07:21,  2.00s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 836/1056 [28:57<07:20,  2.00s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 837/1056 [28:59<07:24,  2.03s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 838/1056 [29:01<07:28,  2.06s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 839/1056 [29:03<07:27,  2.06s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 840/1056 [29:05<07:29,  2.08s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 841/1056 [29:07<07:27,  2.08s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 842/1056 [29:09<07:28,  2.10s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 843/1056 [29:12<07:30,  2.12s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 844/1056 [29:14<07:28,  2.11s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 845/1056 [29:16<07:18,  2.08s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 846/1056 [29:18<07:19,  2.09s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 847/1056 [29:20<07:22,  2.12s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 848/1056 [29:22<07:17,  2.11s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 849/1056 [29:24<07:14,  2.10s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 850/1056 [29:26<07:15,  2.11s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.901515151515151e-06, 'epoch': 2.41}\u001b[0m\n",
      "\u001b[34m80%|████████  | 850/1056 [29:26<07:15,  2.11s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 851/1056 [29:28<07:06,  2.08s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 852/1056 [29:30<06:59,  2.05s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 853/1056 [29:32<06:56,  2.05s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 854/1056 [29:34<06:57,  2.07s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 855/1056 [29:37<06:57,  2.08s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 856/1056 [29:39<06:56,  2.08s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 857/1056 [29:41<06:54,  2.08s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 858/1056 [29:43<06:53,  2.09s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 859/1056 [29:45<06:58,  2.12s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 860/1056 [29:47<06:51,  2.10s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 861/1056 [29:49<06:57,  2.14s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 862/1056 [29:51<06:55,  2.14s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 863/1056 [29:53<06:43,  2.09s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 864/1056 [29:56<06:39,  2.08s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 865/1056 [29:58<06:38,  2.09s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 866/1056 [30:00<06:29,  2.05s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 867/1056 [30:02<06:33,  2.08s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 868/1056 [30:04<06:33,  2.09s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 869/1056 [30:06<06:44,  2.17s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 870/1056 [30:08<06:37,  2.13s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 871/1056 [30:10<06:38,  2.15s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 872/1056 [30:12<06:27,  2.10s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 873/1056 [30:15<06:23,  2.10s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 874/1056 [30:17<06:16,  2.07s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 875/1056 [30:19<06:17,  2.08s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 876/1056 [30:21<06:09,  2.05s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 877/1056 [30:23<06:06,  2.05s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 878/1056 [30:25<06:06,  2.06s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 879/1056 [30:27<06:03,  2.05s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 880/1056 [30:29<06:00,  2.05s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 881/1056 [30:31<06:01,  2.07s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 882/1056 [30:33<05:59,  2.06s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 883/1056 [30:35<05:53,  2.04s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 884/1056 [30:37<05:50,  2.04s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 885/1056 [30:39<05:50,  2.05s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 886/1056 [30:41<05:50,  2.06s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 887/1056 [30:43<05:46,  2.05s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 888/1056 [30:45<05:45,  2.06s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 889/1056 [30:47<05:42,  2.05s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 890/1056 [30:50<05:48,  2.10s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 891/1056 [30:52<05:45,  2.10s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 892/1056 [30:54<05:43,  2.09s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 893/1056 [30:56<05:34,  2.05s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 894/1056 [30:58<05:34,  2.06s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 895/1056 [31:00<05:39,  2.11s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 896/1056 [31:02<05:32,  2.08s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 897/1056 [31:04<05:29,  2.07s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 898/1056 [31:06<05:25,  2.06s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 899/1056 [31:08<05:26,  2.08s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 900/1056 [31:10<05:24,  2.08s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.954545454545455e-06, 'epoch': 2.55}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 900/1056 [31:10<05:24,  2.08s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 901/1056 [31:12<05:17,  2.05s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 902/1056 [31:14<05:18,  2.07s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 903/1056 [31:16<05:08,  2.02s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 904/1056 [31:18<05:06,  2.02s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 905/1056 [31:20<05:10,  2.06s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 906/1056 [31:22<05:09,  2.06s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 907/1056 [31:25<05:11,  2.09s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 908/1056 [31:27<05:08,  2.09s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 909/1056 [31:29<05:06,  2.09s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 910/1056 [31:31<05:02,  2.07s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 911/1056 [31:33<04:56,  2.04s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 912/1056 [31:35<04:58,  2.07s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 913/1056 [31:37<04:56,  2.07s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 914/1056 [31:39<04:55,  2.08s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 915/1056 [31:41<04:54,  2.09s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 916/1056 [31:43<04:50,  2.08s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 917/1056 [31:45<04:49,  2.08s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 918/1056 [31:48<04:48,  2.09s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 919/1056 [31:49<04:38,  2.03s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 920/1056 [31:52<04:41,  2.07s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 921/1056 [31:54<04:47,  2.13s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 922/1056 [31:56<04:42,  2.10s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 923/1056 [31:58<04:39,  2.10s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 924/1056 [32:00<04:39,  2.12s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 925/1056 [32:02<04:33,  2.09s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 926/1056 [32:04<04:35,  2.12s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 927/1056 [32:06<04:31,  2.11s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 928/1056 [32:08<04:24,  2.06s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 929/1056 [32:10<04:21,  2.06s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 930/1056 [32:13<04:20,  2.07s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 931/1056 [32:15<04:18,  2.07s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 932/1056 [32:17<04:12,  2.04s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 933/1056 [32:19<04:09,  2.03s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 934/1056 [32:20<04:03,  1.99s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 935/1056 [32:23<04:04,  2.02s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 936/1056 [32:25<04:05,  2.04s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 937/1056 [32:27<04:10,  2.10s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 938/1056 [32:29<04:04,  2.07s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 939/1056 [32:31<04:02,  2.07s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 940/1056 [32:33<03:56,  2.04s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 941/1056 [32:35<03:54,  2.04s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 942/1056 [32:37<03:52,  2.04s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 943/1056 [32:39<03:49,  2.03s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 944/1056 [32:41<03:48,  2.04s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 945/1056 [32:43<03:49,  2.06s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 946/1056 [32:45<03:47,  2.07s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 947/1056 [32:47<03:44,  2.06s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 948/1056 [32:49<03:41,  2.05s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 949/1056 [32:51<03:39,  2.05s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 950/1056 [32:54<03:40,  2.08s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.0075757575757576e-06, 'epoch': 2.69}\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 950/1056 [32:54<03:40,  2.08s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 951/1056 [32:56<03:39,  2.09s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 952/1056 [32:58<03:39,  2.11s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 953/1056 [33:00<03:38,  2.12s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 954/1056 [33:02<03:34,  2.10s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 955/1056 [33:04<03:32,  2.11s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 956/1056 [33:06<03:29,  2.10s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 957/1056 [33:08<03:23,  2.06s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 958/1056 [33:10<03:21,  2.06s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 959/1056 [33:12<03:20,  2.06s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 960/1056 [33:14<03:20,  2.08s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 961/1056 [33:16<03:16,  2.06s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 962/1056 [33:19<03:20,  2.13s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 963/1056 [33:21<03:14,  2.09s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 964/1056 [33:23<03:13,  2.10s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 965/1056 [33:25<03:11,  2.11s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 966/1056 [33:27<03:08,  2.09s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 967/1056 [33:29<03:04,  2.08s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 968/1056 [33:31<03:01,  2.07s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 969/1056 [33:33<03:03,  2.11s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 970/1056 [33:35<03:02,  2.12s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 971/1056 [33:38<02:59,  2.11s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 972/1056 [33:40<02:59,  2.13s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 973/1056 [33:42<02:56,  2.13s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 974/1056 [33:44<02:51,  2.09s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 975/1056 [33:46<02:51,  2.12s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 976/1056 [33:48<02:50,  2.13s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 977/1056 [33:50<02:45,  2.09s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 978/1056 [33:52<02:40,  2.06s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 979/1056 [33:54<02:40,  2.08s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 980/1056 [33:57<02:40,  2.11s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 981/1056 [33:59<02:35,  2.08s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 982/1056 [34:01<02:33,  2.07s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 983/1056 [34:03<02:32,  2.09s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 984/1056 [34:05<02:33,  2.13s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 985/1056 [34:07<02:30,  2.13s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 986/1056 [34:09<02:27,  2.11s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 987/1056 [34:11<02:24,  2.10s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 988/1056 [34:13<02:20,  2.06s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 989/1056 [34:15<02:19,  2.08s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 990/1056 [34:17<02:17,  2.08s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 991/1056 [34:20<02:16,  2.10s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 992/1056 [34:22<02:15,  2.11s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 993/1056 [34:24<02:13,  2.12s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 994/1056 [34:26<02:11,  2.12s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 995/1056 [34:28<02:08,  2.11s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 996/1056 [34:30<02:06,  2.11s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 997/1056 [34:32<02:05,  2.12s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 998/1056 [34:34<02:02,  2.11s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 999/1056 [34:36<01:59,  2.09s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1000/1056 [34:39<02:00,  2.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.0606060606060608e-06, 'epoch': 2.83}\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1000/1056 [34:39<02:00,  2.15s/it]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1001/1056 [34:41<02:04,  2.26s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1002/1056 [34:43<01:57,  2.18s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1003/1056 [34:45<01:53,  2.15s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1004/1056 [34:47<01:51,  2.14s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1005/1056 [34:50<01:48,  2.13s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1006/1056 [34:52<01:44,  2.10s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1007/1056 [34:54<01:41,  2.08s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1008/1056 [34:56<01:38,  2.06s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1009/1056 [34:57<01:34,  2.02s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1010/1056 [35:00<01:32,  2.02s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1011/1056 [35:02<01:31,  2.02s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1012/1056 [35:04<01:29,  2.02s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1013/1056 [35:06<01:26,  2.01s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1014/1056 [35:08<01:25,  2.03s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1015/1056 [35:10<01:24,  2.06s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1016/1056 [35:12<01:21,  2.04s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1017/1056 [35:14<01:19,  2.03s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1018/1056 [35:16<01:17,  2.05s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1019/1056 [35:18<01:16,  2.08s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1020/1056 [35:20<01:15,  2.09s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1021/1056 [35:22<01:12,  2.08s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1022/1056 [35:24<01:10,  2.06s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1023/1056 [35:26<01:07,  2.03s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1024/1056 [35:28<01:06,  2.07s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1025/1056 [35:30<01:02,  2.03s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1026/1056 [35:32<01:01,  2.04s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1027/1056 [35:35<01:01,  2.13s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1028/1056 [35:37<01:00,  2.14s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1029/1056 [35:39<00:58,  2.16s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1030/1056 [35:41<00:54,  2.11s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1031/1056 [35:43<00:53,  2.15s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1032/1056 [35:45<00:50,  2.12s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1033/1056 [35:47<00:48,  2.09s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1034/1056 [35:49<00:45,  2.08s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1035/1056 [35:51<00:43,  2.05s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1036/1056 [35:53<00:40,  2.02s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1037/1056 [35:55<00:37,  2.00s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1038/1056 [35:57<00:36,  2.05s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1039/1056 [35:59<00:33,  2.00s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1040/1056 [36:01<00:32,  2.02s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1041/1056 [36:03<00:30,  2.03s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1042/1056 [36:06<00:28,  2.05s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1043/1056 [36:08<00:27,  2.13s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1044/1056 [36:10<00:26,  2.17s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1045/1056 [36:12<00:23,  2.12s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1046/1056 [36:14<00:21,  2.11s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1047/1056 [36:16<00:19,  2.13s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1048/1056 [36:18<00:17,  2.13s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1049/1056 [36:21<00:15,  2.14s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1050/1056 [36:23<00:12,  2.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.1363636363636364e-07, 'epoch': 2.98}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1050/1056 [36:23<00:12,  2.16s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1051/1056 [36:25<00:10,  2.11s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1052/1056 [36:27<00:08,  2.14s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1053/1056 [36:29<00:06,  2.13s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1054/1056 [36:31<00:04,  2.10s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1055/1056 [36:33<00:02,  2.11s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1056/1056 [36:35<00:00,  2.10s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 2196.3496, 'train_samples_per_second': 3.855, 'train_steps_per_second': 0.481, 'train_loss': 240617766.78787878, 'epoch': 2.99}\u001b[0m\n",
      "\u001b[34m100%|██████████| 1056/1056 [36:36<00:00,  2.10s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1056/1056 [36:36<00:00,  2.08s/it]\u001b[0m\n",
      "\u001b[34m2025-07-19 21:23:01,562 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-07-19 21:23:01,563 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-07-19 21:23:01,563 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-07-19 21:23:20 Uploading - Uploading generated training model\n",
      "2025-07-19 21:23:20 Completed - Training job completed\n",
      "Training seconds: 2553\n",
      "Billable seconds: 2553\n",
      "Reward model artefact: s3://sagemaker-us-west-2-842747873802/rm-1752957473/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "import time, sagemaker\n",
    "\n",
    "role   = sagemaker.get_execution_role()\n",
    "sess   = sagemaker.Session()\n",
    "\n",
    "reward_est = HuggingFace(\n",
    "    entry_point         = \"train_reward.py\",\n",
    "    source_dir          = \"./\",          # has script + requirements.txt\n",
    "    role                = role,\n",
    "    instance_type       = \"ml.g5.12xlarge\",\n",
    "    instance_count      = 1,\n",
    "    transformers_version= \"4.49.0\",\n",
    "    pytorch_version     = \"2.5.1\",\n",
    "    py_version          = \"py311\",\n",
    "    environment = {\n",
    "        \"HF_EULA_ACCEPT\": \"true\",\n",
    "        \"HF_TOKEN\"      : \"\",     # 🔑 your token\n",
    "        \"BASE_ID\"       : \"meta-llama/Meta-Llama-3-8B\",  # or …-Instruct\n",
    "        \"TRAIN_FILE\"    : s3_rm,\n",
    "        \"PYTORCH_CUDA_ALLOC_CONF\": \"expandable_segments:True\"\n",
    "    }\n",
    ")\n",
    "\n",
    "reward_est.fit(job_name=f\"rm-{int(time.time())}\")\n",
    "\n",
    "rm_uri = reward_est.model_data\n",
    "print(\"Reward model artefact:\", rm_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc601a85-0202-4cfb-81d6-18b8463fa9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnableNetworkIsolation: False\n",
      "VpcConfig: None\n",
      "Image URI: 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:2.5.1-transformers4.49.0-gpu-py311-cu124-ubuntu22.04\n"
     ]
    }
   ],
   "source": [
    "import boto3, pprint\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "tj = sm.describe_training_job(TrainingJobName=\"rm-1752812991\")\n",
    "print(\"EnableNetworkIsolation:\", tj[\"EnableNetworkIsolation\"])\n",
    "print(\"VpcConfig:\", tj.get(\"VpcConfig\"))\n",
    "print(\"Image URI:\", tj[\"AlgorithmSpecification\"][\"TrainingImage\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da79e615-6822-47ff-bbe1-1a90ea35729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: ppo-1753210881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 19:02:37 Starting - Starting the training job\n",
      "2025-07-22 19:02:37 Pending - Training job waiting for capacity............\n",
      "2025-07-22 19:04:22 Pending - Preparing the instances for training.........\n",
      "2025-07-22 19:06:08 Downloading - Downloading the training image........................\n",
      "2025-07-22 19:09:50 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mCUDA compat package should be installed for NVIDIA driver smaller than 550.144.03\u001b[0m\n",
      "\u001b[34mCurrent installed NVIDIA driver version is 550.163.01\u001b[0m\n",
      "\u001b[34mSkipping CUDA compat setup as newer NVIDIA driver is installed\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:41,093 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:41,159 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:41,169 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:41,171 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:46,198 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: trl>=0.8.9 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.15.2)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==1.9.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.29.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bitsandbytes>=0.42.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.45.5)\u001b[0m\n",
      "\u001b[34mCollecting s3fs<2025.0,>=2024.12.0 (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading s3fs-2024.12.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (7.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (2.5.1+cu124)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.9.0->-r requirements.txt (line 3)) (0.5.3)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore<3.0.0,>=2.5.4 (from s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading aiobotocore-2.23.1-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec==2024.12.0.* in /opt/conda/lib/python3.11/site-packages (from s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (2024.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (3.11.18)\u001b[0m\n",
      "\u001b[34mCollecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.38.47,>=1.38.40 (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.38.46-py3-none-any.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0.0,>=6.0.0 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (6.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.17.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (2.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (0.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.20.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.38.47,>=1.38.40->aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (3.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from trl>=0.8.9->-r requirements.txt (line 2)) (13.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers>=4.46.0 in /opt/conda/lib/python3.11/site-packages (from trl>=0.8.9->-r requirements.txt (line 2)) (4.49.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft->-r requirements.txt (line 4)) (4.66.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (3.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (20.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (2.2.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (2.32.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (4.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (3.1.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 5)) (3.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 5)) (2025.1.31)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl>=0.8.9->-r requirements.txt (line 2)) (2024.11.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl>=0.8.9->-r requirements.txt (line 2)) (0.21.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate==1.9.0->-r requirements.txt (line 3)) (3.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2025.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl>=0.8.9->-r requirements.txt (line 2)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl>=0.8.9->-r requirements.txt (line 2)) (2.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl>=0.8.9->-r requirements.txt (line 2)) (0.1.2)\u001b[0m\n",
      "\u001b[34mDownloading accelerate-1.9.0-py3-none-any.whl (367 kB)\u001b[0m\n",
      "\u001b[34mDownloading s3fs-2024.12.0-py3-none-any.whl (30 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiobotocore-2.23.1-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34mDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.38.46-py3-none-any.whl (13.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.7/13.7 MB 134.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: aioitertools, botocore, aiobotocore, accelerate, s3fs\u001b[0m\n",
      "\u001b[34mAttempting uninstall: botocore\u001b[0m\n",
      "\u001b[34mFound existing installation: botocore 1.37.11\u001b[0m\n",
      "\u001b[34mUninstalling botocore-1.37.11:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled botocore-1.37.11\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 1.4.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-1.4.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-1.4.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: s3fs\u001b[0m\n",
      "\u001b[34mFound existing installation: s3fs 0.4.2\u001b[0m\n",
      "\u001b[34mUninstalling s3fs-0.4.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled s3fs-0.4.2\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mawscli 1.38.11 requires botocore==1.37.11, but you have botocore 1.38.46 which is incompatible.\u001b[0m\n",
      "\u001b[34mboto3 1.37.11 requires botocore<1.38.0,>=1.37.11, but you have botocore 1.38.46 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-1.9.0 aiobotocore-2.23.1 aioitertools-0.12.0 botocore-1.38.46 s3fs-2024.12.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:49,922 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:49,922 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:50,012 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:50,091 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:50,167 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:50,178 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"reward\": \"/opt/ml/input/data/reward\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"reward\": {\n",
      "            \"ContentType\": \"application/x-tar\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.48xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"ppo-1753210881\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-842747873802/ppo-1753210881/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_ppo\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 192,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.48xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_ppo.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_ppo.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"reward\":{\"ContentType\":\"application/x-tar\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"reward\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.48xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_ppo\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=192\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-842747873802/ppo-1753210881/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"reward\":\"/opt/ml/input/data/reward\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.48xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"reward\":{\"ContentType\":\"application/x-tar\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"ppo-1753210881\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-842747873802/ppo-1753210881/source/sourcedir.tar.gz\",\"module_name\":\"train_ppo\",\"network_interface_name\":\"eth0\",\"num_cpus\":192,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_ppo.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_REWARD=/opt/ml/input/data/reward\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.11 train_ppo.py\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:50,180 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-07-22 19:10:50,180 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mNote: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  25%|██▌       | 1/4 [00:05<00:16,  5.49s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 2/4 [00:09<00:08,  4.47s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.08s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [00:14<00:00,  2.95s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [00:14<00:00,  3.52s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.75s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.87s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.90s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.43s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.59s/it]\u001b[0m\n",
      "\u001b[34mWARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Meta-Llama-3-8B', and no v_head weight is found. This IS expected if you are not resuming PPO training.\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.69s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  2.00s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:06<00:02,  2.10s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.72s/it]\u001b[0m\n",
      "\u001b[34mSome weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/142k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 142k/142k [00:00<00:00, 34.2MB/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2822 examples [00:00, 737419.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/2822 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 2822/2822 [00:00<00:00, 36355.26 examples/s]\u001b[0m\n",
      "\u001b[34m===training policy===\u001b[0m\n",
      "\u001b[34m0%|          | 0/1059 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\u001b[0m\n",
      "\u001b[34mSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_ppo.py\", line 296, in <module>\u001b[0m\n",
      "\u001b[34mtrainer.train()                   # no prompts/epochs args in 0.15 API\u001b[0m\n",
      "\u001b[34m^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/trl/trainer/ppo_trainer.py\", line 458, in train\u001b[0m\n",
      "\u001b[34mfull_value, _, _ = get_reward(\u001b[0m\n",
      "\u001b[34m^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^\n",
      "  File \"/opt/ml/code/train_ppo.py\", line 71, in _safe_get_reward\u001b[0m\n",
      "\u001b[34mreward_logits = model.score(hs)\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^^^^^^\n",
      "  File \"/opt/ml/code/train_ppo.py\", line 176, in _score\u001b[0m\n",
      "\u001b[34mreturn v_head(hidden_states)[0]\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\u001b[0m\n",
      "\u001b[34mreturn self._call_impl(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\u001b[0m\n",
      "\u001b[34mreturn forward_call(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/trl/models/modeling_value_head.py\", line 58, in forward\u001b[0m\n",
      "\u001b[34moutput = self.summary(output)\u001b[0m\n",
      "\u001b[34m^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\u001b[0m\n",
      "\u001b[34mreturn self._call_impl(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\u001b[0m\n",
      "\u001b[34mreturn forward_call(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 125, in forward\u001b[0m\n",
      "\u001b[34mreturn F.linear(input, self.weight, self.bias)\u001b[0m\n",
      "\u001b[34m^^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^^^\u001b[0m\n",
      "\u001b[34mRuntimeError: mat1 and mat2 shapes cannot be multiplied (8x64 and 4096x1)\u001b[0m\n",
      "\u001b[34m0%|          | 0/1059 [00:06<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2025-07-22 19:11:40,927 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-07-22 19:11:40,927 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-07-22 19:11:40,928 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2025-07-22 19:11:40,928 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"RuntimeError: mat1 and mat2 shapes cannot be multiplied (8x64 and 4096x1)\n",
      " 0%|          | 0/1059 [00:06<?, ?it/s]\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.11 train_ppo.py\"\u001b[0m\n",
      "\u001b[34m2025-07-22 19:11:40,928 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2025-07-22 19:13:17 Uploading - Uploading generated training model\n",
      "2025-07-22 19:13:20 Failed - Training job failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">34</span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>},                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span>)                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>34 ppo_est.fit(                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>inputs   = {<span style=\"color: #808000; text-decoration-color: #808000\">\"reward\"</span>: reward_data},            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># ← defines the channel</span>                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>job_name = <span style=\"color: #808000; text-decoration-color: #808000\">f\"ppo-{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(time.time())<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>,                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span>)                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">telemetry_logging.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">168</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>caught_ex = e                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> caught_ex:                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>168 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> caught_ex                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> response  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># pylint: disable=W0150</span>                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>logger.debug(                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">telemetry_logging.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>start_timer = perf_counter()                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Call the original function</span>                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>139 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>response = func(*args, **kwargs)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>stop_timer = perf_counter()                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>elapsed = stop_timer - start_timer                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>extra += <span style=\"color: #808000; text-decoration-color: #808000\">f\"&amp;x-latency={</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">round</span>(elapsed,<span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pipeline_context.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">346</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _StepArguments(retrieve_caller_name(self_instance), run_func, *args,    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">345 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>346 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> run_func(*args, **kwargs)                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">347 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">349 </span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1411</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1408 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>wait = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1409 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>forward_to_mlflow_tracking_server = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1410 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> wait:                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1411 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.latest_training_job.wait(logs=logs)                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1412 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1413 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> forward_to_mlflow_tracking_server:                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1414 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">sagemaker.mlflow.forward_sagemaker_metrics</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> log_sagemaker_job  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2796</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wait</span>                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2793 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>logs = log_string_map[logs]                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If logs are requested, call logs_for_jobs.</span>                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2795 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> logs != <span style=\"color: #808000; text-decoration-color: #808000\">\"None\"</span>:                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2796 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.logs_for_job(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.job_name, wait=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, log_type=logs)  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2797 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.wait_for_job(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.job_name)                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2799 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6158</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">logs_for_job</span>                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6155 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">exceptions.CapacityError: If the training job fails with CapacityError.</span>       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6156 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">exceptions.UnexpectedStatusException: If waiting and the training job fails.</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6157 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6158 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_logs_for_job(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, job_name, wait, poll, log_type, timeout)                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">logs_for_processing_job</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, job_name, wait=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, poll=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>):                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6161 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Display logs for a given processing job, optionally tailing them until the is</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8771</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_logs_for_job</span>               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8768 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>last_profiler_rule_statuses = profiler_rule_statuses                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8769 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8770 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> wait:                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>8771 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_check_job_status(job_name, description, <span style=\"color: #808000; text-decoration-color: #808000\">\"TrainingJobStatus\"</span>)                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8772 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dot:                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8773 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>()                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8774 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Customers are not billed for hardware provisioning, so billable time is less t</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8835</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_job_status</span>           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8832 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>allowed_statuses=[<span style=\"color: #808000; text-decoration-color: #808000\">\"Completed\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"Stopped\"</span>],                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8833 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>actual_status=status,                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8834 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>8835 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> exceptions.UnexpectedStatusException(                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8836 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>message=message,                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8837 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>allowed_statuses=[<span style=\"color: #808000; text-decoration-color: #808000\">\"Completed\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"Stopped\"</span>],                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8838 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>actual_status=status,                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">UnexpectedStatusException: </span>Error for Training job ppo-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1753210881</span>: Failed. Reason: AlgorithmError: \n",
       "ExecuteUserScriptError:\n",
       "ExitCode <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "ErrorMessage \"RuntimeError: mat1 and mat2 shapes cannot be multiplied <span style=\"font-weight: bold\">(</span>8x64 and 4096x1<span style=\"font-weight: bold\">)</span>\n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>%|          | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1059</span> <span style=\"font-weight: bold\">[</span>00:06&lt;?, ?it/s<span style=\"font-weight: bold\">]</span>\"\n",
       "Command <span style=\"color: #008700; text-decoration-color: #008700\">\"/opt/conda/bin/python3.11 train_ppo.py\"</span>, exit code: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Check troubleshooting guide for common errors: \n",
       "<span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m34\u001b[0m                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│   \u001b[0m},                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m32 \u001b[0m)                                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m33 \u001b[0m                                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m34 ppo_est.fit(                                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   \u001b[0minputs   = {\u001b[33m\"\u001b[0m\u001b[33mreward\u001b[0m\u001b[33m\"\u001b[0m: reward_data},            \u001b[2m# ← defines the channel\u001b[0m                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   \u001b[0mjob_name = \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mppo-\u001b[0m\u001b[33m{\u001b[0m\u001b[96mint\u001b[0m(time.time())\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m,                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m37 \u001b[0m)                                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/\u001b[0m\u001b[1;33mtelemetry_logging.py\u001b[0m:\u001b[94m168\u001b[0m in \u001b[92mwrapper\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcaught_ex = e                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m caught_ex:                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m168 \u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m caught_ex                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m response  \u001b[2m# pylint: disable=W0150\u001b[0m                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlogger.debug(                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/\u001b[0m\u001b[1;33mtelemetry_logging.py\u001b[0m:\u001b[94m139\u001b[0m in \u001b[92mwrapper\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mstart_timer = perf_counter()                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# Call the original function\u001b[0m                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   │   │   │   \u001b[0mresponse = func(*args, **kwargs)                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mstop_timer = perf_counter()                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0melapsed = stop_timer - start_timer                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mextra += \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m&x-latency=\u001b[0m\u001b[33m{\u001b[0m\u001b[96mround\u001b[0m(elapsed,\u001b[90m \u001b[0m\u001b[94m2\u001b[0m)\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/\u001b[0m\u001b[1;33mpipeline_context.py\u001b[0m:\u001b[94m346\u001b[0m in \u001b[92mwrapper\u001b[0m    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m343 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m344 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _StepArguments(retrieve_caller_name(self_instance), run_func, *args,    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m345 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m346 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m run_func(*args, **kwargs)                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m347 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m348 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m349 \u001b[0m                                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m1411\u001b[0m in \u001b[92mfit\u001b[0m                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1408 \u001b[0m\u001b[2m│   │   │   \u001b[0mwait = \u001b[94mTrue\u001b[0m                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1409 \u001b[0m\u001b[2m│   │   │   \u001b[0mforward_to_mlflow_tracking_server = \u001b[94mTrue\u001b[0m                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1410 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m wait:                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1411 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job.wait(logs=logs)                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1412 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1413 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m forward_to_mlflow_tracking_server:                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1414 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msagemaker\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmlflow\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mforward_sagemaker_metrics\u001b[0m \u001b[94mimport\u001b[0m log_sagemaker_job  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m2796\u001b[0m in \u001b[92mwait\u001b[0m                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2793 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogs = log_string_map[logs]                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2794 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# If logs are requested, call logs_for_jobs.\u001b[0m                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2795 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m logs != \u001b[33m\"\u001b[0m\u001b[33mNone\u001b[0m\u001b[33m\"\u001b[0m:                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m2796 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.logs_for_job(\u001b[96mself\u001b[0m.job_name, wait=\u001b[94mTrue\u001b[0m, log_type=logs)  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2797 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2798 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.wait_for_job(\u001b[96mself\u001b[0m.job_name)                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2799 \u001b[0m                                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m6158\u001b[0m in \u001b[92mlogs_for_job\u001b[0m                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6155 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.CapacityError: If the training job fails with CapacityError.\u001b[0m       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6156 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6157 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m6158 \u001b[2m│   │   \u001b[0m_logs_for_job(\u001b[96mself\u001b[0m, job_name, wait, poll, log_type, timeout)                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6159 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6160 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mlogs_for_processing_job\u001b[0m(\u001b[96mself\u001b[0m, job_name, wait=\u001b[94mFalse\u001b[0m, poll=\u001b[94m10\u001b[0m):                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6161 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Display logs for a given processing job, optionally tailing them until the is\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m8771\u001b[0m in \u001b[92m_logs_for_job\u001b[0m               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8768 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlast_profiler_rule_statuses = profiler_rule_statuses                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8769 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8770 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m wait:                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m8771 \u001b[2m│   │   \u001b[0m_check_job_status(job_name, description, \u001b[33m\"\u001b[0m\u001b[33mTrainingJobStatus\u001b[0m\u001b[33m\"\u001b[0m)                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8772 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dot:                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8773 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m()                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8774 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Customers are not billed for hardware provisioning, so billable time is less t\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m8835\u001b[0m in \u001b[92m_check_job_status\u001b[0m           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8832 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8833 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mactual_status=status,                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8834 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m8835 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m exceptions.UnexpectedStatusException(                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8836 \u001b[0m\u001b[2m│   │   │   \u001b[0mmessage=message,                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8837 \u001b[0m\u001b[2m│   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8838 \u001b[0m\u001b[2m│   │   │   \u001b[0mactual_status=status,                                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mUnexpectedStatusException: \u001b[0mError for Training job ppo-\u001b[1;36m1753210881\u001b[0m: Failed. Reason: AlgorithmError: \n",
       "ExecuteUserScriptError:\n",
       "ExitCode \u001b[1;36m1\u001b[0m\n",
       "ErrorMessage \"RuntimeError: mat1 and mat2 shapes cannot be multiplied \u001b[1m(\u001b[0m8x64 and 4096x1\u001b[1m)\u001b[0m\n",
       " \u001b[1;36m0\u001b[0m%|          | \u001b[1;36m0\u001b[0m/\u001b[1;36m1059\u001b[0m \u001b[1m[\u001b[0m00:06<?, ?it/s\u001b[1m]\u001b[0m\"\n",
       "Command \u001b[38;2;0;135;0m\"/opt/conda/bin/python3.11 train_ppo.py\"\u001b[0m, exit code: \u001b[1;36m1\u001b[0m. Check troubleshooting guide for common errors: \n",
       "\u001b[4;38;2;0;105;255mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import time, sagemaker, boto3, os, pathlib\n",
    "\n",
    "s3_prompts = f\"s3://{bucket}/{prefix}/data/ppo_prompts.jsonl\"\n",
    "rm_uri     = f\"s3://sagemaker-us-west-2-842747873802/rm-1752957473/output/model.tar.gz\"\n",
    "\n",
    "# reward-model artefact → input channel\n",
    "reward_data = TrainingInput(\n",
    "    rm_uri,\n",
    "    content_type=\"application/x-tar\",\n",
    "    distribution=\"FullyReplicated\",\n",
    ")\n",
    "\n",
    "ppo_est = HuggingFace(\n",
    "    entry_point         = \"train_ppo.py\",\n",
    "    source_dir          = \"./\",\n",
    "    role                = role,\n",
    "    instance_type       = \"ml.g5.48xlarge\",\n",
    "    instance_count      = 1,\n",
    "    transformers_version= \"4.49.0\",\n",
    "    pytorch_version     = \"2.5.1\",\n",
    "    py_version          = \"py311\",\n",
    "    environment = {\n",
    "        \"HF_EULA_ACCEPT\": \"true\",\n",
    "        \"HF_TOKEN\"      : \"\",\n",
    "        \"BASE_ID\"       : \"meta-llama/Meta-Llama-3-8B\",\n",
    "        \"PROMPT_FILE\"   : s3_prompts,              # S3 prompts file\n",
    "        # NO RM_DIR here — the script will use SM_CHANNEL_REWARD\n",
    "        \"PYTORCH_CUDA_ALLOC_CONF\": \"expandable_segments:True\",\n",
    "    },\n",
    ")\n",
    "\n",
    "ppo_est.fit(\n",
    "    inputs   = {\"reward\": reward_data},            # ← defines the channel\n",
    "    job_name = f\"ppo-{int(time.time())}\",\n",
    ")\n",
    "\n",
    "ppo_uri = ppo_est.model_data\n",
    "print(\"PPO artefact:\", ppo_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0635f2be-14f3-43ad-85ed-7ec13514f15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/opt/ml/input/data/reward': No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ls', '-R', '/opt/ml/input/data/reward'], returncode=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d709e3-7389-4f62-b8f5-b159c8d694a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: accelerate 0.21.0\n",
      "Uninstalling accelerate-0.21.0:\n",
      "  Successfully uninstalled accelerate-0.21.0\n",
      "\u001b[33mWARNING: Skipping trl as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: transformers 4.38.2\n",
      "Uninstalling transformers-4.38.2:\n",
      "  Successfully uninstalled transformers-4.38.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires accelerate<0.22.0,>=0.21.0, which is not installed.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "autogluon-timeseries 1.1.1 requires accelerate<0.22.0,>=0.21.0, which is not installed.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires transformers[sentencepiece]<4.41.0,>=4.38.0, but you have transformers 4.49.0 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires transformers[sentencepiece]<4.41.0,>=4.38.0, but you have transformers 4.49.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y accelerate trl transformers\n",
    "!pip install -q \"transformers==4.49.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33678be0-1914-4077-87f3-48f9fc87dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "arn:aws:iam::842747873802:role/service-role/AmazonSageMaker-ExecutionRole-20250624T170706 sagemaker-us-west-2-842747873802 us-west-2\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 0. House-keeping:  choose a role, bucket and paths\n",
    "# ================================================================\n",
    "import sagemaker, boto3, json, os, pathlib, time\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()                    # studio-execution-role\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()                           # or hard-code yours\n",
    "prefix = \"llama3_math_rlhf\"                              # keep all assets here\n",
    "\n",
    "BASE_ID = \"meta-textgeneration-llama-3-8b\"    # JumpStart Neuron model\n",
    "print(role, bucket, region)\n",
    "s3_rm = f\"s3://{bucket}/{prefix}/data/rm.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83900f9d-4fab-4eda-bc70-b784901f5813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: ppo-1753231906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-23 00:53:06 Starting - Starting the training job\n",
      "2025-07-23 00:53:06 Pending - Training job waiting for capacity............\n",
      "2025-07-23 00:54:41 Pending - Preparing the instances for training......\n",
      "2025-07-23 00:56:02 Downloading - Downloading input data...\n",
      "2025-07-23 00:56:22 Downloading - Downloading the training image..................\n",
      "2025-07-23 00:59:39 Training - Training image download completed. Training in progress.......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mCUDA compat package should be installed for NVIDIA driver smaller than 550.144.03\u001b[0m\n",
      "\u001b[34mCurrent installed NVIDIA driver version is 550.163.01\u001b[0m\n",
      "\u001b[34mSkipping CUDA compat setup as newer NVIDIA driver is installed\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:33,563 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:33,627 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:33,637 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:33,639 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:38,653 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting trl==0.19.1 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading trl-0.19.1-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.29.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bitsandbytes>=0.42.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.45.5)\u001b[0m\n",
      "\u001b[34mCollecting s3fs<2025.0,>=2024.12.0 (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading s3fs-2024.12.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: peft>=0.11 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from trl==0.19.1->-r requirements.txt (line 1)) (1.4.0)\u001b[0m\n",
      "\u001b[34mCollecting transformers>=4.51.0 (from trl==0.19.1->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore<3.0.0,>=2.5.4 (from s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading aiobotocore-2.23.1-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec==2024.12.0.* in /opt/conda/lib/python3.11/site-packages (from s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (2024.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (3.11.18)\u001b[0m\n",
      "\u001b[34mCollecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.38.47,>=1.38.40 (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.38.46-py3-none-any.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0.0,>=6.0.0 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (6.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.17.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (2.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (0.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.20.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.38.47,>=1.38.40->aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore<3.0.0,>=2.5.4->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (1.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2025.0,>=2024.12.0->-r requirements.txt (line 8)) (3.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (3.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (20.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (2.2.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (2.32.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (4.66.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 5)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (4.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch<3,>=2.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes>=0.42.0->-r requirements.txt (line 7)) (2.5.1+cu124)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes>=0.42.0->-r requirements.txt (line 7)) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes>=0.42.0->-r requirements.txt (line 7)) (3.1.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes>=0.42.0->-r requirements.txt (line 7)) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes>=0.42.0->-r requirements.txt (line 7)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft>=0.11->-r requirements.txt (line 10)) (7.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft>=0.11->-r requirements.txt (line 10)) (0.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 5)) (3.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 5)) (2025.1.31)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.51.0->trl==0.19.1->-r requirements.txt (line 1)) (2024.11.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.51.0->trl==0.19.1->-r requirements.txt (line 1)) (0.21.1)\u001b[0m\n",
      "\u001b[34mCollecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes>=0.42.0->-r requirements.txt (line 7)) (3.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2025.1)\u001b[0m\n",
      "\u001b[34mDownloading trl-0.19.1-py3-none-any.whl (376 kB)\u001b[0m\n",
      "\u001b[34mDownloading s3fs-2024.12.0-py3-none-any.whl (30 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiobotocore-2.23.1-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34mDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.38.46-py3-none-any.whl (13.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.7/13.7 MB 143.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 114.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\u001b[0m\n",
      "\u001b[34mDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 144.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: hf-xet, aioitertools, huggingface-hub, botocore, aiobotocore, transformers, s3fs, trl\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.29.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.29.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.29.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: botocore\u001b[0m\n",
      "\u001b[34mFound existing installation: botocore 1.37.11\u001b[0m\n",
      "\u001b[34mUninstalling botocore-1.37.11:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled botocore-1.37.11\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.49.0\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.49.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.49.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: s3fs\u001b[0m\n",
      "\u001b[34mFound existing installation: s3fs 0.4.2\u001b[0m\n",
      "\u001b[34mUninstalling s3fs-0.4.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled s3fs-0.4.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: trl\u001b[0m\n",
      "\u001b[34mFound existing installation: trl 0.15.2\u001b[0m\n",
      "\u001b[34mUninstalling trl-0.15.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled trl-0.15.2\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mawscli 1.38.11 requires botocore==1.37.11, but you have botocore 1.38.46 which is incompatible.\u001b[0m\n",
      "\u001b[34mboto3 1.37.11 requires botocore<1.38.0,>=1.37.11, but you have botocore 1.38.46 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiobotocore-2.23.1 aioitertools-0.12.0 botocore-1.38.46 hf-xet-1.1.5 huggingface-hub-0.33.4 s3fs-2024.12.0 transformers-4.53.3 trl-0.19.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:49,221 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:49,221 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:49,304 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:49,380 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:49,456 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:49,467 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"reward\": \"/opt/ml/input/data/reward\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"reward\": {\n",
      "            \"ContentType\": \"application/x-tar\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.48xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"ppo-1753231906\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-842747873802/ppo-1753231906/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_ppo\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 192,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.48xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_ppo.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_ppo.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"reward\":{\"ContentType\":\"application/x-tar\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"reward\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.48xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_ppo\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=192\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-842747873802/ppo-1753231906/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"reward\":\"/opt/ml/input/data/reward\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.48xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"reward\":{\"ContentType\":\"application/x-tar\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"ppo-1753231906\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-842747873802/ppo-1753231906/source/sourcedir.tar.gz\",\"module_name\":\"train_ppo\",\"network_interface_name\":\"eth0\",\"num_cpus\":192,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_ppo.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_REWARD=/opt/ml/input/data/reward\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.11 train_ppo.py\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:49,469 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-07-23 01:00:49,469 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mNote: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.66s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.67s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.67s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.14s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\u001b[0m\n",
      "\u001b[34mWARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Meta-Llama-3-8B', and no v_head weight is found. This IS expected if you are not resuming PPO training.\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.90s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.93s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.94s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.46s/it]\u001b[0m\n",
      "\u001b[34mSome weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/142k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 142k/142k [00:00<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2822 examples [00:00, 815567.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/2822 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 2822/2822 [00:00<00:00, 35930.91 examples/s]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_ppo.py\", line 131, in <module>\u001b[0m\n",
      "\u001b[34mtrainer = PPOTrainer(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/trl/trainer/ppo_trainer.py\", line 229, in __init__\u001b[0m\n",
      "\u001b[34mdisable_dropout_in_model(module)\u001b[0m\n",
      "\u001b[34mFile \"/opt/conda/lib/python3.11/site-packages/trl/trainer/utils.py\", line 848, in disable_dropout_in_model\u001b[0m\n",
      "\u001b[34mfor module in model.modules():\u001b[0m\n",
      "\u001b[34m^^^^^^^^\u001b[0m\n",
      "\u001b[34m^^^^^\u001b[0m\n",
      "\u001b[34mFile \"/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 1100, in __getattr__\u001b[0m\n",
      "\u001b[34mraise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\u001b[0m\n",
      "\u001b[34mAttributeError: PreTrainedTokenizerFast has no attribute modules\u001b[0m\n",
      "\u001b[34m2025-07-23 01:01:44,900 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-07-23 01:01:44,901 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-07-23 01:01:44,902 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2025-07-23 01:01:44,902 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"raise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\n",
      " AttributeError: PreTrainedTokenizerFast has no attribute modules\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.11 train_ppo.py\"\u001b[0m\n",
      "\u001b[34m2025-07-23 01:01:44,902 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2025-07-23 01:05:49 Uploading - Uploading generated training model\n",
      "2025-07-23 01:05:49 Failed - Training job failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">34</span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>},                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span>)                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>34 ppo_est.fit(                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>inputs   = {<span style=\"color: #808000; text-decoration-color: #808000\">\"reward\"</span>: reward_data},            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># ← defines the channel</span>                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>job_name = <span style=\"color: #808000; text-decoration-color: #808000\">f\"ppo-{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(time.time())<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>,                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span>)                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">telemetry_logging.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">168</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>caught_ex = e                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> caught_ex:                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>168 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> caught_ex                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> response  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># pylint: disable=W0150</span>                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>logger.debug(                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">telemetry_logging.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>start_timer = perf_counter()                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Call the original function</span>                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>139 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>response = func(*args, **kwargs)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>stop_timer = perf_counter()                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>elapsed = stop_timer - start_timer                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>extra += <span style=\"color: #808000; text-decoration-color: #808000\">f\"&amp;x-latency={</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">round</span>(elapsed,<span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pipeline_context.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">346</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _StepArguments(retrieve_caller_name(self_instance), run_func, *args,    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">345 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>346 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> run_func(*args, **kwargs)                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">347 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">349 </span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1411</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1408 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>wait = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1409 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>forward_to_mlflow_tracking_server = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1410 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> wait:                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1411 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.latest_training_job.wait(logs=logs)                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1412 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1413 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> forward_to_mlflow_tracking_server:                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1414 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">sagemaker.mlflow.forward_sagemaker_metrics</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> log_sagemaker_job  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">estimator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2796</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wait</span>                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2793 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>logs = log_string_map[logs]                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If logs are requested, call logs_for_jobs.</span>                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2795 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> logs != <span style=\"color: #808000; text-decoration-color: #808000\">\"None\"</span>:                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2796 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.logs_for_job(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.job_name, wait=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, log_type=logs)  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2797 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.wait_for_job(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.job_name)                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2799 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6158</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">logs_for_job</span>                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6155 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">exceptions.CapacityError: If the training job fails with CapacityError.</span>       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6156 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">exceptions.UnexpectedStatusException: If waiting and the training job fails.</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6157 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6158 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_logs_for_job(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, job_name, wait, poll, log_type, timeout)                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">logs_for_processing_job</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, job_name, wait=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, poll=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>):                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6161 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Display logs for a given processing job, optionally tailing them until the is</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8771</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_logs_for_job</span>               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8768 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>last_profiler_rule_statuses = profiler_rule_statuses                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8769 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8770 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> wait:                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>8771 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_check_job_status(job_name, description, <span style=\"color: #808000; text-decoration-color: #808000\">\"TrainingJobStatus\"</span>)                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8772 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dot:                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8773 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>()                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8774 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Customers are not billed for hardware provisioning, so billable time is less t</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8835</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_job_status</span>           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8832 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>allowed_statuses=[<span style=\"color: #808000; text-decoration-color: #808000\">\"Completed\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"Stopped\"</span>],                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8833 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>actual_status=status,                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8834 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>8835 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> exceptions.UnexpectedStatusException(                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8836 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>message=message,                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8837 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>allowed_statuses=[<span style=\"color: #808000; text-decoration-color: #808000\">\"Completed\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"Stopped\"</span>],                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8838 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>actual_status=status,                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">UnexpectedStatusException: </span>Error for Training job ppo-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1753231906</span>: Failed. Reason: AlgorithmError: \n",
       "ExecuteUserScriptError:\n",
       "ExitCode <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "ErrorMessage <span style=\"color: #008700; text-decoration-color: #008700\">\"raise AttributeError</span><span style=\"color: #008700; text-decoration-color: #008700; font-weight: bold\">(</span><span style=\"color: #008700; text-decoration-color: #008700\">f\"</span><span style=\"font-weight: bold\">{</span>self.__class__.__name__<span style=\"font-weight: bold\">}</span> has no attribute <span style=\"font-weight: bold\">{</span>key<span style=\"font-weight: bold\">}</span>\"<span style=\"font-weight: bold\">)</span>\n",
       " AttributeError: PreTrainedTokenizerFast has no attribute modules\"\n",
       "Command <span style=\"color: #008700; text-decoration-color: #008700\">\"/opt/conda/bin/python3.11 train_ppo.py\"</span>, exit code: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Check troubleshooting guide for common errors: \n",
       "<span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m34\u001b[0m                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│   \u001b[0m},                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m32 \u001b[0m)                                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m33 \u001b[0m                                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m34 ppo_est.fit(                                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   \u001b[0minputs   = {\u001b[33m\"\u001b[0m\u001b[33mreward\u001b[0m\u001b[33m\"\u001b[0m: reward_data},            \u001b[2m# ← defines the channel\u001b[0m                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   \u001b[0mjob_name = \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mppo-\u001b[0m\u001b[33m{\u001b[0m\u001b[96mint\u001b[0m(time.time())\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m,                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m37 \u001b[0m)                                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/\u001b[0m\u001b[1;33mtelemetry_logging.py\u001b[0m:\u001b[94m168\u001b[0m in \u001b[92mwrapper\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcaught_ex = e                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m caught_ex:                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m168 \u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m caught_ex                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m response  \u001b[2m# pylint: disable=W0150\u001b[0m                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlogger.debug(                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/\u001b[0m\u001b[1;33mtelemetry_logging.py\u001b[0m:\u001b[94m139\u001b[0m in \u001b[92mwrapper\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mstart_timer = perf_counter()                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# Call the original function\u001b[0m                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   │   │   │   \u001b[0mresponse = func(*args, **kwargs)                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mstop_timer = perf_counter()                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0melapsed = stop_timer - start_timer                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mextra += \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m&x-latency=\u001b[0m\u001b[33m{\u001b[0m\u001b[96mround\u001b[0m(elapsed,\u001b[90m \u001b[0m\u001b[94m2\u001b[0m)\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/\u001b[0m\u001b[1;33mpipeline_context.py\u001b[0m:\u001b[94m346\u001b[0m in \u001b[92mwrapper\u001b[0m    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m343 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m344 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _StepArguments(retrieve_caller_name(self_instance), run_func, *args,    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m345 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m346 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m run_func(*args, **kwargs)                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m347 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m348 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m349 \u001b[0m                                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m1411\u001b[0m in \u001b[92mfit\u001b[0m                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1408 \u001b[0m\u001b[2m│   │   │   \u001b[0mwait = \u001b[94mTrue\u001b[0m                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1409 \u001b[0m\u001b[2m│   │   │   \u001b[0mforward_to_mlflow_tracking_server = \u001b[94mTrue\u001b[0m                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1410 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m wait:                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1411 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job.wait(logs=logs)                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1412 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1413 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m forward_to_mlflow_tracking_server:                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1414 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msagemaker\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmlflow\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mforward_sagemaker_metrics\u001b[0m \u001b[94mimport\u001b[0m log_sagemaker_job  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m2796\u001b[0m in \u001b[92mwait\u001b[0m                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2793 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogs = log_string_map[logs]                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2794 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# If logs are requested, call logs_for_jobs.\u001b[0m                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2795 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m logs != \u001b[33m\"\u001b[0m\u001b[33mNone\u001b[0m\u001b[33m\"\u001b[0m:                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m2796 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.logs_for_job(\u001b[96mself\u001b[0m.job_name, wait=\u001b[94mTrue\u001b[0m, log_type=logs)  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2797 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2798 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.wait_for_job(\u001b[96mself\u001b[0m.job_name)                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2799 \u001b[0m                                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m6158\u001b[0m in \u001b[92mlogs_for_job\u001b[0m                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6155 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.CapacityError: If the training job fails with CapacityError.\u001b[0m       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6156 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6157 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m6158 \u001b[2m│   │   \u001b[0m_logs_for_job(\u001b[96mself\u001b[0m, job_name, wait, poll, log_type, timeout)                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6159 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6160 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mlogs_for_processing_job\u001b[0m(\u001b[96mself\u001b[0m, job_name, wait=\u001b[94mFalse\u001b[0m, poll=\u001b[94m10\u001b[0m):                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6161 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Display logs for a given processing job, optionally tailing them until the is\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m8771\u001b[0m in \u001b[92m_logs_for_job\u001b[0m               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8768 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlast_profiler_rule_statuses = profiler_rule_statuses                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8769 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8770 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m wait:                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m8771 \u001b[2m│   │   \u001b[0m_check_job_status(job_name, description, \u001b[33m\"\u001b[0m\u001b[33mTrainingJobStatus\u001b[0m\u001b[33m\"\u001b[0m)                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8772 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dot:                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8773 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m()                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8774 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Customers are not billed for hardware provisioning, so billable time is less t\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/sagemaker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m8835\u001b[0m in \u001b[92m_check_job_status\u001b[0m           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8832 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8833 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mactual_status=status,                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8834 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m8835 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m exceptions.UnexpectedStatusException(                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8836 \u001b[0m\u001b[2m│   │   │   \u001b[0mmessage=message,                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8837 \u001b[0m\u001b[2m│   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m8838 \u001b[0m\u001b[2m│   │   │   \u001b[0mactual_status=status,                                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mUnexpectedStatusException: \u001b[0mError for Training job ppo-\u001b[1;36m1753231906\u001b[0m: Failed. Reason: AlgorithmError: \n",
       "ExecuteUserScriptError:\n",
       "ExitCode \u001b[1;36m1\u001b[0m\n",
       "ErrorMessage \u001b[38;2;0;135;0m\"raise AttributeError\u001b[0m\u001b[1;38;2;0;135;0m(\u001b[0m\u001b[38;2;0;135;0mf\"\u001b[0m\u001b[1m{\u001b[0mself.__class__.__name__\u001b[1m}\u001b[0m has no attribute \u001b[1m{\u001b[0mkey\u001b[1m}\u001b[0m\"\u001b[1m)\u001b[0m\n",
       " AttributeError: PreTrainedTokenizerFast has no attribute modules\"\n",
       "Command \u001b[38;2;0;135;0m\"/opt/conda/bin/python3.11 train_ppo.py\"\u001b[0m, exit code: \u001b[1;36m1\u001b[0m. Check troubleshooting guide for common errors: \n",
       "\u001b[4;38;2;0;105;255mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import time, sagemaker, boto3, os, pathlib\n",
    "\n",
    "s3_prompts = f\"s3://{bucket}/{prefix}/data/ppo_prompts.jsonl\"\n",
    "rm_uri     = f\"s3://sagemaker-us-west-2-842747873802/rm-1752957473/output/model.tar.gz\"\n",
    "\n",
    "# reward-model artefact → input channel\n",
    "reward_data = TrainingInput(\n",
    "    rm_uri,\n",
    "    content_type=\"application/x-tar\",\n",
    "    distribution=\"FullyReplicated\",\n",
    ")\n",
    "\n",
    "ppo_est = HuggingFace(\n",
    "    entry_point         = \"train_ppo.py\",\n",
    "    source_dir          = \"./\",\n",
    "    role                = role,\n",
    "    instance_type       = \"ml.g5.48xlarge\",\n",
    "    instance_count      = 1,\n",
    "    transformers_version= \"4.49.0\",\n",
    "    pytorch_version     = \"2.5.1\",\n",
    "    py_version          = \"py311\",\n",
    "    environment = {\n",
    "        \"HF_EULA_ACCEPT\": \"true\",\n",
    "        \"HF_TOKEN\"      : \"\",\n",
    "        \"BASE_ID\"       : \"meta-llama/Meta-Llama-3-8B\",\n",
    "        \"PROMPT_FILE\"   : s3_prompts,              # S3 prompts file\n",
    "        # NO RM_DIR here — the script will use SM_CHANNEL_REWARD\n",
    "        \"PYTORCH_CUDA_ALLOC_CONF\": \"expandable_segments:True\",\n",
    "    },\n",
    ")\n",
    "\n",
    "ppo_est.fit(\n",
    "    inputs   = {\"reward\": reward_data},            # ← defines the channel\n",
    "    job_name = f\"ppo-{int(time.time())}\",\n",
    ")\n",
    "\n",
    "ppo_uri = ppo_est.model_data\n",
    "print(\"PPO artefact:\", ppo_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72771a10-fb7f-4023-b043-376612a8be14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
